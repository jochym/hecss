[
  {
    "objectID": "monitor_phonons.html",
    "href": "monitor_phonons.html",
    "title": "Phonon convergence monitoring",
    "section": "",
    "text": "Note: The phonon monitoring functions are not complete and are at the alpha level. Thus, they may not work as described or at all.\n\nfrom hecss.monitor import monitor_phonons, plot_bands_file\nfrom matplotlib import pyplot as plt\n\n\nfig, axs = plt.subplots(1,2,figsize=(14,4))\nfor sc, ax in zip(('1x1x1', '2x2x2'), axs):\n    plt.sca(ax)\n    for T in 300, 600, 1200, 3000:\n        plot_bands_file(f'example/VASP_3C-SiC_calculated/{sc}/T_{T}K/phon/cryst.bands', lbl=f'T={T}K')\n    plt.legend()\n    plt.title(f'Supercell: {sc}');\n\n\n\n\n\n\n\n\n\nT = 3000\nsupercell = '2x2x2'\nmonitor_phonons(directory=f'example/VASP_3C-SiC_calculated/{supercell}/phon/', \n                dfset=f'../T_3000K/DFSET.dat', \n                kpath='3C_SiC', charge='3C_SiC', sc=f'../sc/CONTCAR',\n                order=1,     # Change to 2 if you want to monitor cubic potential\n                cutoff=10,   # Interaction range in Bohr. Do not increase too much.\n                born=2,      # Change to None to deactivate \n                             # Born effective charges calculation\n                k_list=None, # Change to string with points (e.g. 'KX') \n                             # to plot selected points\n                once=True,   # Show the plot and exit\n               )",
    "crumbs": [
      "Phonon convergence monitoring"
    ]
  },
  {
    "objectID": "planner.html",
    "href": "planner.html",
    "title": "Temperature scan planner",
    "section": "",
    "text": "source",
    "crumbs": [
      "Temperature scan planner"
    ]
  },
  {
    "objectID": "planner.html#simulate-with-stats.normal-random-variable",
    "href": "planner.html#simulate-with-stats.normal-random-variable",
    "title": "Temperature scan planner",
    "section": "Simulate with stats.normal random variable",
    "text": "Simulate with stats.normal random variable\n\n# semilogx()\nplt.figure(figsize=(10,6))\nrv = stats.norm\nN = 100_000\nplan = plan_T_scan(50, 250, 32, N)\n\nel = np.zeros(0)\nfor c, (l, s, n) in enumerate(tqdm(plan)):\n    el = np.append(el, rv.rvs(loc=l, scale=s, size=n))\n\nskip = len(el)//2000\nskip = int(max(1, skip))\nfor s in el[::skip]:\n    plt.axvline(s, ymin=0.95, ymax=0.98, ls='-', color='r', alpha=0.1)\n    \nNF = sum([sf for _, _, sf in plan])\ncounts, bins = np.histogram(el, bins='auto', density=True)\nplt.hist(bins[:-1], bins, weights=NF*counts, color='C0', alpha=0.3);",
    "crumbs": [
      "Temperature scan planner"
    ]
  },
  {
    "objectID": "planner.html#run-with-hecss-sampler",
    "href": "planner.html#run-with-hecss-sampler",
    "title": "Temperature scan planner",
    "section": "Run with HECSS sampler",
    "text": "Run with HECSS sampler\n\nfrom hecss.core import HECSS\nfrom hecss.util import select_asap_model, create_asap_calculator\nfrom hecss.optimize import make_sampling\nfrom hecss.monitor import plot_stats\n\n\nmodel = select_asap_model('SiC')\nprint(f'Using potential model: {model}')\n\nsys_size = '3x3x3'\nsc = [int(v) for v in sys_size.split('x')]\n\ncryst = bulk('SiC', crystalstructure='zincblende',\n                 a=4.38120844, cubic=True).repeat(tuple(sc))\ncryst.calc = create_asap_calculator(model)\nhecss = HECSS(cryst, lambda : create_asap_calculator(model), pbar=False)\nhecss.estimate_width_scale(10, Tmax=1000);\n\nUsing potential model: MEAM_LAMMPS_KangEunJun_2014_SiC__MO_477506997611_000\n\n\n\nN = 1_000\nplt.figure(figsize=(10,6))\nplan = plan_T_scan(150, 250, len(cryst), N)\n\n\n\n\n\n\n\n\n\nsmpls = {}\nfor T, sig, n in tqdm(plan):\n    # sampler = HECSS_Sampler(cryst, asap3.OpenKIMcalculator(model),\n    #                         T, N=int(n), pbar=tqdm(total=n))\n    smpls[T]=np.array([s[-1] for s in hecss._sampler_ser(T, n)])\n# ell = [np.array([s[-1] for s in sl]) for sl in smpls.values()]\n\n\n\n\n\nell = np.concatenate(list(smpls.values()))\ne_min = ell.min()\ne_max = ell.max()\n\n\nfor T, el in smpls.items():\n    plt.hist(el, bins=50, histtype='step', label=f'{T=:.0f}K', range=(e_min, e_max))\nplt.hist(ell, bins=50, stacked=True, color='C0', alpha=0.25, range=(e_min, e_max))\nplt.legend();\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(10,6))\nif N &lt; 10_000:\n    bins = np.linspace(e_min, e_max, 50)*2/un.kB/3\nelse :\n    bins = 'auto'\ncnt, bins, _ = plt.hist(ell*2/un.kB/3, \n                     bins=bins, density=False, alpha=0.6, label='Total');\nx = np.linspace(bins[0], bins[-1], 300)\ny = np.zeros(x.shape)\ntdx = bins[1]-bins[0]\nfor c, ((T, el), (Tp, sig, n)) in enumerate(zip(smpls.items(), plan)):\n    # bins = 'auto'\n    e = el*2/un.kB/3\n    Tc, Tb, _ = plt.hist(e, bins=bins, density=False, \n                         histtype='step', color=f'C{c+1}');\n    dx = Tb[1]-Tb[0]\n    # plt.plot(x, dx*n*stats.norm.pdf(x, loc=T, scale=sig), color=f'C{c+1}', \n    #          label=f'{T=:.1f}K (N={int(Tc.sum())})')\n    # y += tdx*n*stats.norm.pdf(x, loc=T, scale=sig)\n\n    fit = stats.norm.fit(e)\n    plt.plot(x, dx*n*stats.norm.pdf(x, *fit), color=f'C{c+1}',\n             label=f'{T=:.1f}K (N={int(Tc.sum())})')\n    \n    y += tdx*n*stats.norm.pdf(x, *fit)\n    \n    skip = len(el)//500\n    skip = max(1, skip)\n    for v in e[::skip]:\n        plt.axvline(v, ymin=0.95, ymax=0.98, ls='-', color='r', alpha=0.05)\n    \nplt.plot(x, y, '--', label='Total')\nplt.xlabel('Temperature (K)')\nplt.legend(loc='upper right')\nplt.title('Temperature scan - HECSS generated energies.')\nplt.grid()\nplt.savefig(f'AUX/T_scan_{N=}.pdf')",
    "crumbs": [
      "Temperature scan planner"
    ]
  },
  {
    "objectID": "planner.html#test-temperature-scanning-planner",
    "href": "planner.html#test-temperature-scanning-planner",
    "title": "Temperature scan planner",
    "section": "Test temperature scanning planner",
    "text": "Test temperature scanning planner\n\nN = 1000\nplt.figure(figsize=(8,4))\nplan = plan_T_scan(200, 400, len(cryst), N)\nplt.savefig('AUX/T_scan_plan.pdf', bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nsmpll = []\nfor T, sig, n in tqdm(plan):\n    smpll.append([s for s in hecss.sample(T, n)])\nell = [[s[-1] for s in sl] for sl in smpll]\n\n\n\n\n\nusmp = []\nfor sl in smpll:\n    usmp += sl\n\n\nplt.figure(figsize=(8,4))\nplt.hist([s[-1] for s in usmp], bins='auto', density=True)\nplt.xlabel('Potential energy (meV/at)')\nplt.ylabel('Probability density (meV/at)$^{-1}$')\nplt.title('Temperatures: 200-400K')\nplt.savefig(f'AUX/uniform.pdf', bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nT = 273\nwd = make_sampling(usmp, T, N=4*N, nonzero_w=False, debug=True)\nprint(len(usmp), len(wd))\nplt.legend(loc='upper right', bbox_to_anchor=(1.0, 0.95))\nplt.show();\nplot_stats(wd, T, sqrN=True, show=False)\nplt.savefig(f'AUX/T_scan_{T=:.0f}K.pdf', bbox_inches='tight')\n\n\n\n\n\n\n\n\n3448 3945\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(10,6))\nif N &lt; 1_000:\n    bins = np.linspace(min(flatten(ell)), max(flatten(ell)), 40)*2/un.kB/3\nelse :\n    bins = 'auto'\ncnt, bins, _ = plt.hist(np.array(list(flatten(ell)))*2/un.kB/3, \n                     bins=50, density=False, alpha=0.3, label='Total');\nx = np.linspace(bins[0], bins[-1], 300)\ny = np.zeros(x.shape)\ntdx = bins[1]-bins[0]\nfor c, (el, (T, sig, n)) in enumerate(zip(ell, plan)):\n    e = np.array(el)\n    bins = 'auto'\n    Tc, Tb, _ = plt.hist(e*2/un.kB/3, bins=bins, density=False, \n                         histtype='step', color=f'C{c+1}');\n    dx = Tb[1]-Tb[0]\n    nf = np.sum(Tc)*dx\n    # plt.plot(x, dx*n*stats.norm.pdf(x, loc=T, scale=sig), color=f'C{c+1}', \n    #          label=f'{T=:.1f}K (N={int(Tc.sum())})')\n    # y += tdx*n*stats.norm.pdf(x, loc=T, scale=sig)\n    fit = stats.logistic.fit(e*2/un.kB/3)\n    plt.plot(x, nf*stats.logistic.pdf(x, *fit), color=f'C{c+1}', \n             label=f'{T=:.1f}K (N={int(Tc.sum())})')\n    y += nf*stats.logistic.pdf(x, *fit)\n\n    skip = len(el)//1000\n    skip = max(1, skip)\n    for v in e[::skip]*2/un.kB/3:\n        plt.axvline(v, ymin=0.95, ymax=0.98, ls='-', color='r', alpha=0.05)\n    \nplt.plot(x, y, '--', label='Plan (total)')\nplt.xlabel('Temperature (K)')\nplt.legend(loc='upper right')\nplt.title('Temperature scan - HECSS generated energies.')\nplt.grid()\nplt.savefig(f'AUX/T_scan_{N=}.pdf')\n\n\n\n\n\n\n\n\n\nx = np.linspace(-5, 5, 100)\nplt.plot(x, stats.norm.pdf(x))\nplt.grid()\nplt.axhline(1/8)\nplt.axvline(np.log(3+2*np.sqrt(2)))\nplt.axvline(np.log(3-2*np.sqrt(2)))\nplt.plot(x, stats.logistic.pdf(x))\ns=2\nplt.plot(x, stats.logistic.pdf(x, scale=s))\nplt.axhline(1/(8*s))\nplt.axvline(s*np.log(3+2*np.sqrt(2)))\nplt.axvline(s*np.log(3-2*np.sqrt(2)))\n\n\n\n\n\n\n\n\n\nx = np.linspace(0, 15, 300)\ny = np.zeros(x.shape)\na = np.log(3+2*np.sqrt(2))\na = 1.4\nx0 = 3\nb = 1/8\nnf = 1\nwhile x0 &lt; 15:\n    s = x0*b\n    if x0*(1+b*a)/(1-b*a) &gt; 15:\n        nf = 1.3\n        x0 *= 1.05\n    yy=nf*s*stats.logistic.pdf(x, loc=x0, scale=s)\n    plt.plot(x,yy)\n    y += yy\n    x0 *= (1+a*b)/(1-a*b)\nplt.plot(x,y)\nplt.axhline(1/4); plt.axhline(1/8)\n\n\n\n\n\n\n\n\n\n# semilogx()\nplt.figure(figsize=(10,6))\nrv = stats.norm\nN = 1_000_000\nplan = plan_T_scan(50, 250, 32, N)\n\nel = np.zeros(0)\nfor c, (l, s, n) in enumerate(tqdm(plan)):\n    el = np.append(el, rv.rvs(loc=l, scale=s, size=n))\n\nskip = len(el)//2000\nskip = int(max(1, skip))\nfor s in el[::skip]:\n    plt.axvline(s, ymin=0.95, ymax=0.98, ls='-', color='r', alpha=0.1)\n    \nNF = sum([sf for _, _, sf in plan])\ncounts, bins = np.histogram(el, bins='auto', density=True)\nplt.hist(bins[:-1], bins, weights=NF*counts, color='C0', alpha=0.3);",
    "crumbs": [
      "Temperature scan planner"
    ]
  },
  {
    "objectID": "planner.html#scanning-with-width-instead-of-temperature",
    "href": "planner.html#scanning-with-width-instead-of-temperature",
    "title": "Temperature scan planner",
    "section": "Scanning with width instead of temperature",
    "text": "Scanning with width instead of temperature\n\nUniform distribution",
    "crumbs": [
      "Temperature scan planner"
    ]
  },
  {
    "objectID": "dof_map.html",
    "href": "dof_map.html",
    "title": "Mapping of DOFs to minimal set",
    "section": "",
    "text": "import spglib as spg\nimport ase\nimport ase.io\nimport numpy as np\n\n\nfrom ase import spacegroup as sg\nfrom hecss.util import get_cell_data\n\n\n# cryst = ase.io.read('/home/jochym/cryst/TiO2_hecss/PBE_2x2x4/uc/CONTCAR')\n# cryst = ase.io.read('/home/jochym/cryst/TiO2_hecss/PBE_Tetra/uc/CONTCAR')*(2,2,4)\n# cryst = ase.io.read('/home/pastukh/Czech.calculation/sc/CONTCAR')\ncryst = ase.io.read('example/VASP_3C-SiC_calculated/2x2x2/sc/CONTCAR')\n\n\npuc = spg.find_primitive(get_cell_data(cryst))\ncryst_pc = ase.Atoms(cell=puc[0], scaled_positions=puc[1], numbers=puc[2], pbc=True)\nsym = spg.get_symmetry(get_cell_data(cryst_pc))\nsymds = spg.get_symmetry_dataset(get_cell_data(cryst_pc))\nspg.get_spacegroup(get_cell_data(cryst_pc))\n\n'F-43m (216)'\n\n\n\nSG = sg.get_spacegroup(cryst_pc)\nSG\n\nSpacegroup(216, setting=1)\n\n\n\nsg.get_basis(cryst_pc)\n\narray([[0.75, 0.75, 0.75],\n       [0.  , 0.  , 0.  ]])\n\n\n\neps = 0.01\ndv = eps*np.diag(np.ones(3))\nuvec = {n:v for n, v in zip((0,1,2),dv)}\nuvec\n\n{0: array([0.01, 0.  , 0.  ]),\n 1: array([0.  , 0.01, 0.  ]),\n 2: array([0.  , 0.  , 0.01])}\n\n\n\ndef find_key(val, dic):\n    for k, v in dic.items():\n        if np.allclose(v, val):\n            return k\n\n\neqdir = {}\nfor sp in set(symds['equivalent_atoms']):\n    pci = symds['mapping_to_primitive'][sp]\n    print(sp, pci, puc[1][pci], puc[2][pci])\n    pos = puc[1][pci]\n    m = {}\n    for n, d in uvec.items(): \n        v = pos+d\n        m[n]=set()\n        for elp in SG.equivalent_lattice_points([v]):\n            # if np.allclose(v, elp):\n            #     continue\n            if np.any(elp - pos &lt; 0):\n                continue\n            if np.all(np.abs(elp - pos) &lt; 2*eps):\n                di = v-pos\n                df = elp-pos\n                m[n]|={find_key(elp-pos, uvec)}\n                # print(find_key(v-pos, uvec), '-&gt;',  find_key(elp-pos, uvec))\n    # print(m)\n    for k, v in m.items():\n        print(k, '-&gt;', sorted(v)[0])\n    eqdir[sp] = np.array([sorted(v)[0] for k, v in sorted(m.items())])\nprint(eqdir)    \n# print(SG.tag_sites(cryst_pc.get_scaled_positions()))\n\n0 0 [0.75 0.75 0.75] 6\n0 -&gt; 0\n1 -&gt; 0\n2 -&gt; 0\n1 1 [0. 0. 0.] 14\n0 -&gt; 0\n1 -&gt; 0\n2 -&gt; 0\n{0: array([0, 0, 0]), 1: array([0, 0, 0])}\n\n\n\nat_map = symds['equivalent_atoms'][spg.get_symmetry_dataset(get_cell_data(cryst))['mapping_to_primitive']]\n\n\ndc = cryst.copy()\ndc.rattle()\n\n\ndx = dc.get_positions() - cryst.get_positions()\n\n\nd_avg = {ai:dx[at_map == ai] for ai in set(at_map)}\n\n\nfor ai, eqd in eqdir.items():\n    for di in set(eqd):\n        print(ai, di, d_avg[ai][:,eqd==di].shape, d_avg[ai][:,eqd==di].std())\n\n0 0 (32, 3) 0.0009203960620541905\n1 0 (32, 3) 0.0009473878538096573\n\n\n\ncryst.get_scaled_positions()[np.zeros((64),dtype=int)].shape\n\n(64, 3)\n\n\n\nnp.array(np.zeros((64,2)), dtype=int)\n\narray([[0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0]])",
    "crumbs": [
      "Mapping of DOFs to minimal set"
    ]
  },
  {
    "objectID": "monitor_stats.html",
    "href": "monitor_stats.html",
    "title": "Sampling statistics monitoring",
    "section": "",
    "text": "The two functions are essentially the same except for the live aspect. They display the energy distribution in the sample relative to the target distribution (determined by the temperature). The shaded areas indicate 1,2,3\\(\\sigma\\) intervals for the distribution. The fitted distribution is a gaussian curve fitted to the sample. The the data sets presented here are examples provided in the example/VASP_3C-SiC_calculated/ directory of the source distribution. Refer to the Setup document for information about installation of the source distribution.",
    "crumbs": [
      "Sampling statistics monitoring"
    ]
  },
  {
    "objectID": "monitor_stats.html#interpreting-the-statistics-plot",
    "href": "monitor_stats.html#interpreting-the-statistics-plot",
    "title": "Sampling statistics monitoring",
    "section": "Interpreting the statistics plot",
    "text": "Interpreting the statistics plot\nThe sampling statistics plots show a number of characteristics of the generated sample. The orange bell curve with green central line shows target energy distribution for a given temperature. The shaded orange regions indicate \\(\\sigma, 2\\sigma,\\) and \\(3\\sigma\\) zones around this distribution. The width of the standard deviation band is determined by the squere of the target distribution scaled to the size of the sample and number of bins in the histogram. The blue-shaded bars show population in each bin of the histogram and red dashed curve is a normal distribution fitted to the data points in the sample. In general, both bars of the histogram and fitted distribution should fit inside the \\(3\\sigma\\) band - such distribution should be considered a correct sampling of the target distribution. However, in small samples the statistical fluctuations are large and sometimes this condition is not met. In such cases the size of the variance of the actual bin of the histogram should be considered. This value is not plotted by default, but may be switched on with sqrN=True parameter to plot_stats function. The hi-lo bars on top of histogram bins indicate one standard deviation intervals around the value of the histogram bin. You have to judge for yourself when the dstribution is satisfactorily reproduced. In general \\(2\\sigma\\) bars of the target and the bin should overlap.\n\nfrom hecss.monitor import monitor_stats, plot_stats, load_dfset",
    "crumbs": [
      "Sampling statistics monitoring"
    ]
  },
  {
    "objectID": "monitor_stats.html#single-data-plot",
    "href": "monitor_stats.html#single-data-plot",
    "title": "Sampling statistics monitoring",
    "section": "Single data plot",
    "text": "Single data plot\n\nT = 300\nsupercell = '2x2x2'\nplot_stats(load_dfset(f'example/VASP_3C-SiC_calculated/{supercell}/T_{T:.0f}K/DFSET.dat'), \n           T=T, sqrN=True);",
    "crumbs": [
      "Sampling statistics monitoring"
    ]
  },
  {
    "objectID": "monitor_stats.html#live-plot",
    "href": "monitor_stats.html#live-plot",
    "title": "Sampling statistics monitoring",
    "section": "Live plot",
    "text": "Live plot\nHere, presented with optional once=True argument making it run just once. If you want to actually monitor the calculation live you shoul omit this option.\n\nT = 600\nsupercell = '1x1x1'\nmonitor_stats(T=T, \n              dfset=f'example/VASP_3C-SiC_calculated/{supercell}/T_{T:.0f}K/DFSET.dat',\n              once=True # Show the plot and exit\n             )",
    "crumbs": [
      "Sampling statistics monitoring"
    ]
  },
  {
    "objectID": "monitor_stats.html#multiple-plots",
    "href": "monitor_stats.html#multiple-plots",
    "title": "Sampling statistics monitoring",
    "section": "Multiple plots",
    "text": "Multiple plots\nExample of multiple plots showing all pre-calculated data included in the source package. This example demonstrates how the plot_stats function may be used to build more complex figures (e.g. for inclusion in publication).\n\nfrom glob import glob\nfrom matplotlib import pyplot as plt\n\nfig, axs = plt.subplots(4,2, figsize=(14,14))\n\nfor n, d in enumerate(sorted(\n                glob('example/VASP_3C-SiC_calculated/?x?x?/T_*K'), \n                key=lambda s: (s.split('/')[-2],float(s.split('/')[-1][2:-1])))):\n    T=float(d.split('/')[-1][2:-1])\n    sc = d.split('/')[-2]\n    plt.sca(axs[n%4][n//4])\n    plot_stats(load_dfset(f'{d}/DFSET.dat'), T=T, show=False)\n    plt.text(0.05, 0.8, f'{sc}\\n T={T}K', transform=plt.gca().transAxes)",
    "crumbs": [
      "Sampling statistics monitoring"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core",
    "section": "",
    "text": "Standard interface to the HECSS library. This class encapsulates the actual sampler implemented in the sample method and provides main functionality of the library through the generate method.\n\nsource\n\n\n\n HECSS (cryst, calc, width=None, maxburn=20, w_search=True,\n        disp_dist='normal', directory=None, pbar=False)\n\n*Class encapsulating the sampling and weight generation for the HECSS algorithm.\nCreate the HECSS sampling object. It is intendet to be a single object per crystal cryst used to run samplers for one or more temperatures. The object holds data common to all samplers (structure, calculator etc.). The other parameters are set per sampler. The set of samplers, indexed by temperature is hold inside the HECSS object in the samplers dictionary.\n\n\n\ncryst : crystal structure (ASE Atoms object)\ncalc : calculator, must be re-usable, otherwise must be calculator generator\nwidth : eta, displacement scaling parameter, approx 1.0\nmaxburn : max. number of initial burn-in samples\nw_search : use width/eta searching algorithm (default True)\ndisp_dist : use different distribution instead of stats.norm as the displacement distribution.\ndirectory : basic calculation directory used by directory based calculators\npbar : show progress bar during calculations*\n\n\nsource\n\n\n\n\n\n HECSS.estimate_width_scale (n=1, Tmin=0, Tmax=600, set_scale=True,\n                             pbar=None, nwork=None)\n\n*Estimate coefficient between temperature and displacement scale (eta). Calculate energy increase from the n temperatures uniformly distributed between 0 and Tmax and calculate avarage \\(\\sqrt{E-E0/T}\\) which is a width scale for a given temperature: \\[\n    w = \\eta\\sqrt{T}\n\\] which comes from the assumed approximate relationship: \\[\n    \\frac{E(w(T))-E_0}{T} \\approx \\mathrm{const} = \\eta^2.\n\\]\n\n\n\nn - number of sampling points\nTmin - min sampled temperature\nTmax - max sampled temperature\nset_scale - set scale parameter in the class after run\npbar - show progress bar during calculation\nnwork - if not None, number of parallel workers to use. Only supported for VASP, 0 =&gt; unlimited.\n\n\n\n\n\nif wm_out : mean(eta), std(eta), wm\nelse : mean(eta), std(eta)\nwm - the nx3 array of: [width, Temperature, (E-E0)/nat]*\n\n\nsource\n\n\n\n\n\n HECSS.sample (T, N, sentinel=None, sentinel_args={}, nwork=None,\n               **kwargs)\n\nGenerate N samples using HECSS._sampler_(ser/aio) generator. sentinel parameter is a call-back function which is called on every sample to decide if the iteration should be stopped early. If it returns True the iteration will be stopped and the current list of samples is returned. The sentinel is called after* generating each sample (i.e. first time after first sample is produced). This may take considerable time at the start since first initial and burn-in samples must be produced.\nThe sampling loop may be run for N iterations or indefinitely.\n\n\n\nT : Target temperature in Kelvin\nN : Number of iterations.\nsentinel :\ndelta_sample : Prior width adaptation rate. The default is sufficient in most cases.\nsigma : Range around E0 in sigmas to stop w-serach mode\neqdelta : Max. speed of amplitude correction from step to step (0.05=5%)\neqsigma : Half width of linear part of amplitude correction function.\nxi : strength of the amplitude correction term [0-1]\nchi : strength of the amplitude correction term mixing [0-1]\nxscale_init : Initial values of the amplitude correction coefficients. Array with shape cryst.get_positions().shape. May be also generated with calc_init_xscale function.\nEp0 : T=0 energy (base, no displacements), if None (default) calculate E0.\nmodify : pass your own pre-processing function to modify the structure before calculation. The function must return a (e, f) tuple with energy of the structure (e, scalar) and forces (f, array).\nmodify_args : dictionary of extra arguments to pass to modify function\nsymprec : symmetry detection treshold for spglib functions\ndirectory : (only for VASP calculator) directory for calculations and generated samples. If left as None, the calc/{T_goal:.1f}K/ will be used and the generated samples will be stored in the smpl/{i:04d} subdirectories.\nreuse_base : None or the base calculator created by restarting the ground state config. If None the base will be recalculated at the start of the run. If the value is a calculator - the energy from this calculator will be used as ground state energy for the calculation. Be careful to have the same setup in calc and reuse_base, otherwise the ground state energy and distribution will be wrong.\nverb : print verbose progress messages for interactive use\n\nOutput parameters\n\nwidth_list : Output parameter. If not None, store in passed list the sequence of widths.\ndofmu_list : Output parameter. If not None, store in passed list the array of DOF virials relative to temperature (T_goal).\nxscale_list : Output parameter. If not None, store in passed list the array of amplitude correction coefficients (normalized). May be used to generate xscale_init values with the help of calc_init_xscale function.\n\n\n\n\nThe returns a list of samples from the prior distribution at T=T_goal as list of tuples (number, index, displacement, forces, energy):\n\nnumber : sample number, always increasing\nindex : integer numbering the samples in the smpl subdirectory. Index repeats if the sample must be repeated in the sequence.\ndisplacement : set of atomic displacements (in A) in the sample (numpy array)\nforces : set of forces (in eV/A) generated by the displacement\nenergy : potential energy of the configuration*\n\n\nsource\n\n\n\n\n\n HECSS.generate (S, T=None, sigma_scale=1.0, border=False, probTH=0.25,\n                 Nmul=4, N=None, nonzero_w=True, debug=False)\n\n*Generate new sample with normal energy probability distribution corresponding to temperature T and size of the system inferred from data. The output is generated by multiplying samples passed in S proportionally to the wegihts generated by get_sample_weights and assuming the final dataset will be Nmul times longer (or the length N which takes precedence). If nonzero_w is True the data multiplyers in the range (probTH, 1) will be clamped to 1, to avoid losing low-probability data. This will obviously deform the distribution but may be beneficial for the interaction model constructed from the data. The data on output will be ordered in increasing energy and re-numbered. The configuration index is retained. The work is directly delegated to the make_sampling function.\n\n\n\ndata - list of samples generated by HECSS sampler ([n, i, x, f, e])\nT - temperature in kelvin, mean energy by default\nsigma_scale - scaling factor for variance. Defaults to 1.0.\nborder - make border samples account for unrepresented part of domain\nprobTH - threshold for probability (N*weight) clamping.\nNmul - data multiplication factor. The lenght of output data will be approximately Nmul*len(data).\nN - approximate output data length. Takes precedence over Nmul\nnonzero_w - prevent zero weights for data with weights in (probTH, 1) range\ndebug - plot diagnostic plots\n\n\n\n\nWeighted, sorted by energy and re-numbered samples as a new list. The data in the list is just reference-duplicated, not copied. Thus the data elements should not be modified. The format is the same as the data produced by HECSS sampler.*\n\n\n\n\nThe sampler needs to create a new Atoms object for distorted structures and needs a new calculator for this object. Most calculators support re-usage of the calculator object so you can pass just a calculator created for this purpose. Other, notably asap3.OpenKIMcalculator, modify the calculator object in-place and make it non-reusable. For such cases you need to pass a generator function in this argument which creates a fresh calculator on each call. The simplest variant is to just use lambda to create the anonymous generator (see examples below).\nsampler = HECSS(SiC, lambda : create_asap_calculator(model))\n\n\n\n\n\n\nfrom hecss.core import *\nfrom hecss.monitor import plot_stats, plot_virial_stat, plot_xs_stat, plot_hist\nfrom hecss.monitor import plot_acceptance_history, plot_dofmu_stat\nfrom hecss.util import select_asap_model, create_asap_calculator, calc_init_xscale\nfrom ase.build import bulk\nfrom ase.spacegroup import crystal\n\n\nmodel = select_asap_model('SiC')\n\nsys_size = '1x1x1'\nsys_size = '2x2x2'\nsys_size = '3x3x3'\nsys_size = '4x4x4'\nsys_size = '5x5x5'\n\nsc = [int(v) for v in sys_size.split('x')]\nSiC = bulk('SiC', crystalstructure='zincblende',\n                 a=4.38120844, cubic=True).repeat(tuple(sc))\nSiC.calc = create_asap_calculator(model)\n\n\nsampler = HECSS(SiC, lambda : create_asap_calculator(model), pbar=True)\n\n\nsampler.w_list = []\nm, s, xscl = sampler.estimate_width_scale(500, Tmin=300, Tmax=1000)\nwm = np.array(sampler._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplot_hist(y, '', 0)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nplt.plot(wm[1], y, '.');\nx = linspace(0, 1.05*wm[1].max(), 2)\nfit = np.polyfit(wm[1], y, 1)\nplt.plot(x, np.polyval(fit, x), ':', label=f'{fit[1]:.3g} + {fit[0]:.3g} T')\nplt.axhline(m, ls='--', label=f'{m:.3g}±{s:.3g}')\nplt.axhspan(m-s, m+s, alpha=0.3)\nplt.ylim(m-4*s, m+4*s)\nplt.xlabel('Temperature (K)')\nplt.ylabel('width scale ($\\\\AA/\\\\sqrt{K}$)')\nplt.legend();\n\n\n\n\n\n\n\n\n\nn = 1\nsampler.w_list = []\nplt.semilogx()\nwhile n &lt; 500 :\n    m, s, xscl = sampler.estimate_width_scale(int(n), Tmax=1000)\n    plt.errorbar(n, m, yerr=s, fmt='o', color='C0')\n    n *= 2\nplt.ylim(m-3*s,m+3*s)\nplt.xlabel('Number of samples')\nplt.ylabel('Width')\nplt.title('Width estimation convergence');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsampler.w_list = []\nT = 300\nN = 100\nsamples = sampler.sample(T, N)\nplot_stats(samples, T, sqrN=True)\n\n\n\n\n\n\n\n\n\n\n\n\ndistrib = make_sampling(samples, T, nonzero_w=False, debug=False)\nplt.show()\nplot_stats(distrib, T, sqrN=True)\n\n\n\n\n\n\n\n\n\ndistrib = sampler.generate(samples, T, 3*N)\nplot_stats(distrib, T, sqrN=True)\n\n\n\n\n\n\n\n\n\n\n\n\nomodel = select_asap_model('Universal')\nprint(f'Using potential model: {omodel}')\n\noliv = ase.io.read('data/spinel.POSCAR')\noliv.calc = create_asap_calculator(omodel)\nprint(f'Space group: {spglib.get_spacegroup(get_cell_data(oliv))}')\nprint('Degrees of freedom in supercell:')\nfor sym, cnt in Counter(oliv.get_chemical_symbols()).items():\n    print(f'   {sym:2}: {cnt:3d}')\n\nUsing potential model: LJ_ElliottAkerson_2015_Universal__MO_959249795837_003\nSpace group: Fd-3m (227)\nDegrees of freedom in supercell:\n   Mg:  16\n   O :  32\n   Si:   8\n\n\n\nprint(f'Max. stress: {np.abs(oliv.get_stress()[:3]).max()/un.GPa:.3f} GPa')\nprint(f'Max. force : {np.abs(oliv.get_forces()).max():.3f} eV/A')\n\nMax. stress: 0.881 GPa\nMax. force : 0.002 eV/A\n\n\n\nT = 600\ndofmu = []\nxsl = []\nxi = 1\nchi = 1\nosampler = HECSS(oliv, lambda : create_asap_calculator(omodel))\n\n\nsampler.w_list = []\nm, s, xscl = osampler.estimate_width_scale(500, Tmax=1000)\nwm = np.array(osampler._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplot_hist(y, '', 0)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.plot(wm[1], y, '.');\nx = linspace(0, 1.05*wm[1].max(), 2)\nfit = np.polyfit(wm[1], y, 1)\nplt.plot(x, np.polyval(fit, x), ':', label=f'{fit[1]:.3g} + {fit[0]:.3g} T')\nplt.axhline(m, ls='--', label=f'{m:.3g}±{s:.3g}')\nplt.axhspan(m-s, m+s, alpha=0.3)\nplt.ylim(m-4*s, m+4*s)\nplt.xlabel('Temperature (K)')\nplt.ylabel('width scale ($\\\\AA/\\\\sqrt{K}$)')\nplt.legend();\n\n\n\n\n\n\n\n\n\nn = 1\nosampler.w_list = []\nplt.semilogx()\nwhile n &lt; 500 :\n    m, s, xscl = osampler.estimate_width_scale(int(n), Tmax=1000)\n    plt.errorbar(n, m, yerr=s, fmt='o', color='C0')\n    n *= 2\nplt.ylim(m-3*s,m+3*s)\nplt.xlim(0.9,None)\nplt.xlabel('Number of samples')\nplt.ylabel('Width')\nplt.title('Width estimation convergence');\n\n\n\n\n\n\n\n\n\nN = 5_00\nosamples = [s for s in tqdm(osampler._sampler_ser(T, N, \n                                            dofmu_list=dofmu, xscale_list=xsl), total=N)]\nplot_stats(osamples, T, sqrN=True)",
    "crumbs": [
      "Core"
    ]
  },
  {
    "objectID": "core.html#hecss-class",
    "href": "core.html#hecss-class",
    "title": "Core",
    "section": "",
    "text": "Standard interface to the HECSS library. This class encapsulates the actual sampler implemented in the sample method and provides main functionality of the library through the generate method.\n\nsource\n\n\n\n HECSS (cryst, calc, width=None, maxburn=20, w_search=True,\n        disp_dist='normal', directory=None, pbar=False)\n\n*Class encapsulating the sampling and weight generation for the HECSS algorithm.\nCreate the HECSS sampling object. It is intendet to be a single object per crystal cryst used to run samplers for one or more temperatures. The object holds data common to all samplers (structure, calculator etc.). The other parameters are set per sampler. The set of samplers, indexed by temperature is hold inside the HECSS object in the samplers dictionary.\n\n\n\ncryst : crystal structure (ASE Atoms object)\ncalc : calculator, must be re-usable, otherwise must be calculator generator\nwidth : eta, displacement scaling parameter, approx 1.0\nmaxburn : max. number of initial burn-in samples\nw_search : use width/eta searching algorithm (default True)\ndisp_dist : use different distribution instead of stats.norm as the displacement distribution.\ndirectory : basic calculation directory used by directory based calculators\npbar : show progress bar during calculations*\n\n\nsource\n\n\n\n\n\n HECSS.estimate_width_scale (n=1, Tmin=0, Tmax=600, set_scale=True,\n                             pbar=None, nwork=None)\n\n*Estimate coefficient between temperature and displacement scale (eta). Calculate energy increase from the n temperatures uniformly distributed between 0 and Tmax and calculate avarage \\(\\sqrt{E-E0/T}\\) which is a width scale for a given temperature: \\[\n    w = \\eta\\sqrt{T}\n\\] which comes from the assumed approximate relationship: \\[\n    \\frac{E(w(T))-E_0}{T} \\approx \\mathrm{const} = \\eta^2.\n\\]\n\n\n\nn - number of sampling points\nTmin - min sampled temperature\nTmax - max sampled temperature\nset_scale - set scale parameter in the class after run\npbar - show progress bar during calculation\nnwork - if not None, number of parallel workers to use. Only supported for VASP, 0 =&gt; unlimited.\n\n\n\n\n\nif wm_out : mean(eta), std(eta), wm\nelse : mean(eta), std(eta)\nwm - the nx3 array of: [width, Temperature, (E-E0)/nat]*\n\n\nsource\n\n\n\n\n\n HECSS.sample (T, N, sentinel=None, sentinel_args={}, nwork=None,\n               **kwargs)\n\nGenerate N samples using HECSS._sampler_(ser/aio) generator. sentinel parameter is a call-back function which is called on every sample to decide if the iteration should be stopped early. If it returns True the iteration will be stopped and the current list of samples is returned. The sentinel is called after* generating each sample (i.e. first time after first sample is produced). This may take considerable time at the start since first initial and burn-in samples must be produced.\nThe sampling loop may be run for N iterations or indefinitely.\n\n\n\nT : Target temperature in Kelvin\nN : Number of iterations.\nsentinel :\ndelta_sample : Prior width adaptation rate. The default is sufficient in most cases.\nsigma : Range around E0 in sigmas to stop w-serach mode\neqdelta : Max. speed of amplitude correction from step to step (0.05=5%)\neqsigma : Half width of linear part of amplitude correction function.\nxi : strength of the amplitude correction term [0-1]\nchi : strength of the amplitude correction term mixing [0-1]\nxscale_init : Initial values of the amplitude correction coefficients. Array with shape cryst.get_positions().shape. May be also generated with calc_init_xscale function.\nEp0 : T=0 energy (base, no displacements), if None (default) calculate E0.\nmodify : pass your own pre-processing function to modify the structure before calculation. The function must return a (e, f) tuple with energy of the structure (e, scalar) and forces (f, array).\nmodify_args : dictionary of extra arguments to pass to modify function\nsymprec : symmetry detection treshold for spglib functions\ndirectory : (only for VASP calculator) directory for calculations and generated samples. If left as None, the calc/{T_goal:.1f}K/ will be used and the generated samples will be stored in the smpl/{i:04d} subdirectories.\nreuse_base : None or the base calculator created by restarting the ground state config. If None the base will be recalculated at the start of the run. If the value is a calculator - the energy from this calculator will be used as ground state energy for the calculation. Be careful to have the same setup in calc and reuse_base, otherwise the ground state energy and distribution will be wrong.\nverb : print verbose progress messages for interactive use\n\nOutput parameters\n\nwidth_list : Output parameter. If not None, store in passed list the sequence of widths.\ndofmu_list : Output parameter. If not None, store in passed list the array of DOF virials relative to temperature (T_goal).\nxscale_list : Output parameter. If not None, store in passed list the array of amplitude correction coefficients (normalized). May be used to generate xscale_init values with the help of calc_init_xscale function.\n\n\n\n\nThe returns a list of samples from the prior distribution at T=T_goal as list of tuples (number, index, displacement, forces, energy):\n\nnumber : sample number, always increasing\nindex : integer numbering the samples in the smpl subdirectory. Index repeats if the sample must be repeated in the sequence.\ndisplacement : set of atomic displacements (in A) in the sample (numpy array)\nforces : set of forces (in eV/A) generated by the displacement\nenergy : potential energy of the configuration*\n\n\nsource\n\n\n\n\n\n HECSS.generate (S, T=None, sigma_scale=1.0, border=False, probTH=0.25,\n                 Nmul=4, N=None, nonzero_w=True, debug=False)\n\n*Generate new sample with normal energy probability distribution corresponding to temperature T and size of the system inferred from data. The output is generated by multiplying samples passed in S proportionally to the wegihts generated by get_sample_weights and assuming the final dataset will be Nmul times longer (or the length N which takes precedence). If nonzero_w is True the data multiplyers in the range (probTH, 1) will be clamped to 1, to avoid losing low-probability data. This will obviously deform the distribution but may be beneficial for the interaction model constructed from the data. The data on output will be ordered in increasing energy and re-numbered. The configuration index is retained. The work is directly delegated to the make_sampling function.\n\n\n\ndata - list of samples generated by HECSS sampler ([n, i, x, f, e])\nT - temperature in kelvin, mean energy by default\nsigma_scale - scaling factor for variance. Defaults to 1.0.\nborder - make border samples account for unrepresented part of domain\nprobTH - threshold for probability (N*weight) clamping.\nNmul - data multiplication factor. The lenght of output data will be approximately Nmul*len(data).\nN - approximate output data length. Takes precedence over Nmul\nnonzero_w - prevent zero weights for data with weights in (probTH, 1) range\ndebug - plot diagnostic plots\n\n\n\n\nWeighted, sorted by energy and re-numbered samples as a new list. The data in the list is just reference-duplicated, not copied. Thus the data elements should not be modified. The format is the same as the data produced by HECSS sampler.*\n\n\n\n\nThe sampler needs to create a new Atoms object for distorted structures and needs a new calculator for this object. Most calculators support re-usage of the calculator object so you can pass just a calculator created for this purpose. Other, notably asap3.OpenKIMcalculator, modify the calculator object in-place and make it non-reusable. For such cases you need to pass a generator function in this argument which creates a fresh calculator on each call. The simplest variant is to just use lambda to create the anonymous generator (see examples below).\nsampler = HECSS(SiC, lambda : create_asap_calculator(model))\n\n\n\n\n\n\nfrom hecss.core import *\nfrom hecss.monitor import plot_stats, plot_virial_stat, plot_xs_stat, plot_hist\nfrom hecss.monitor import plot_acceptance_history, plot_dofmu_stat\nfrom hecss.util import select_asap_model, create_asap_calculator, calc_init_xscale\nfrom ase.build import bulk\nfrom ase.spacegroup import crystal\n\n\nmodel = select_asap_model('SiC')\n\nsys_size = '1x1x1'\nsys_size = '2x2x2'\nsys_size = '3x3x3'\nsys_size = '4x4x4'\nsys_size = '5x5x5'\n\nsc = [int(v) for v in sys_size.split('x')]\nSiC = bulk('SiC', crystalstructure='zincblende',\n                 a=4.38120844, cubic=True).repeat(tuple(sc))\nSiC.calc = create_asap_calculator(model)\n\n\nsampler = HECSS(SiC, lambda : create_asap_calculator(model), pbar=True)\n\n\nsampler.w_list = []\nm, s, xscl = sampler.estimate_width_scale(500, Tmin=300, Tmax=1000)\nwm = np.array(sampler._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplot_hist(y, '', 0)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nplt.plot(wm[1], y, '.');\nx = linspace(0, 1.05*wm[1].max(), 2)\nfit = np.polyfit(wm[1], y, 1)\nplt.plot(x, np.polyval(fit, x), ':', label=f'{fit[1]:.3g} + {fit[0]:.3g} T')\nplt.axhline(m, ls='--', label=f'{m:.3g}±{s:.3g}')\nplt.axhspan(m-s, m+s, alpha=0.3)\nplt.ylim(m-4*s, m+4*s)\nplt.xlabel('Temperature (K)')\nplt.ylabel('width scale ($\\\\AA/\\\\sqrt{K}$)')\nplt.legend();\n\n\n\n\n\n\n\n\n\nn = 1\nsampler.w_list = []\nplt.semilogx()\nwhile n &lt; 500 :\n    m, s, xscl = sampler.estimate_width_scale(int(n), Tmax=1000)\n    plt.errorbar(n, m, yerr=s, fmt='o', color='C0')\n    n *= 2\nplt.ylim(m-3*s,m+3*s)\nplt.xlabel('Number of samples')\nplt.ylabel('Width')\nplt.title('Width estimation convergence');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsampler.w_list = []\nT = 300\nN = 100\nsamples = sampler.sample(T, N)\nplot_stats(samples, T, sqrN=True)\n\n\n\n\n\n\n\n\n\n\n\n\ndistrib = make_sampling(samples, T, nonzero_w=False, debug=False)\nplt.show()\nplot_stats(distrib, T, sqrN=True)\n\n\n\n\n\n\n\n\n\ndistrib = sampler.generate(samples, T, 3*N)\nplot_stats(distrib, T, sqrN=True)\n\n\n\n\n\n\n\n\n\n\n\n\nomodel = select_asap_model('Universal')\nprint(f'Using potential model: {omodel}')\n\noliv = ase.io.read('data/spinel.POSCAR')\noliv.calc = create_asap_calculator(omodel)\nprint(f'Space group: {spglib.get_spacegroup(get_cell_data(oliv))}')\nprint('Degrees of freedom in supercell:')\nfor sym, cnt in Counter(oliv.get_chemical_symbols()).items():\n    print(f'   {sym:2}: {cnt:3d}')\n\nUsing potential model: LJ_ElliottAkerson_2015_Universal__MO_959249795837_003\nSpace group: Fd-3m (227)\nDegrees of freedom in supercell:\n   Mg:  16\n   O :  32\n   Si:   8\n\n\n\nprint(f'Max. stress: {np.abs(oliv.get_stress()[:3]).max()/un.GPa:.3f} GPa')\nprint(f'Max. force : {np.abs(oliv.get_forces()).max():.3f} eV/A')\n\nMax. stress: 0.881 GPa\nMax. force : 0.002 eV/A\n\n\n\nT = 600\ndofmu = []\nxsl = []\nxi = 1\nchi = 1\nosampler = HECSS(oliv, lambda : create_asap_calculator(omodel))\n\n\nsampler.w_list = []\nm, s, xscl = osampler.estimate_width_scale(500, Tmax=1000)\nwm = np.array(osampler._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplot_hist(y, '', 0)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.plot(wm[1], y, '.');\nx = linspace(0, 1.05*wm[1].max(), 2)\nfit = np.polyfit(wm[1], y, 1)\nplt.plot(x, np.polyval(fit, x), ':', label=f'{fit[1]:.3g} + {fit[0]:.3g} T')\nplt.axhline(m, ls='--', label=f'{m:.3g}±{s:.3g}')\nplt.axhspan(m-s, m+s, alpha=0.3)\nplt.ylim(m-4*s, m+4*s)\nplt.xlabel('Temperature (K)')\nplt.ylabel('width scale ($\\\\AA/\\\\sqrt{K}$)')\nplt.legend();\n\n\n\n\n\n\n\n\n\nn = 1\nosampler.w_list = []\nplt.semilogx()\nwhile n &lt; 500 :\n    m, s, xscl = osampler.estimate_width_scale(int(n), Tmax=1000)\n    plt.errorbar(n, m, yerr=s, fmt='o', color='C0')\n    n *= 2\nplt.ylim(m-3*s,m+3*s)\nplt.xlim(0.9,None)\nplt.xlabel('Number of samples')\nplt.ylabel('Width')\nplt.title('Width estimation convergence');\n\n\n\n\n\n\n\n\n\nN = 5_00\nosamples = [s for s in tqdm(osampler._sampler_ser(T, N, \n                                            dofmu_list=dofmu, xscale_list=xsl), total=N)]\nplot_stats(osamples, T, sqrN=True)",
    "crumbs": [
      "Core"
    ]
  },
  {
    "objectID": "lammps_tutorial.html",
    "href": "lammps_tutorial.html",
    "title": "LAMMPS Tutorial",
    "section": "",
    "text": "HECSS sampler may be used in multiple ways. Three main modes are:\n\nJupyter notebook\n(I)Python scripts\nCommand line programs included with the HECSS library. See the CLI sction for more information.\n\nProbably the easiest way to start is a notebook path presented here. You can quite easily convert your notebooks to more sophisticated python scripts by saving them as such from the JupyterLab file menu (File/Save and Export as/Executable script). The CLI route is also fairly simple, but limits the use of the library to pre-packaged procedures with limited configurability.\n\nPreamble\nEvery non-trivial python program starts with a series of import statements. Here, we import HECSS class from the main part of the library, plot_stats diagnostic plotting function from the hecss.monitor sub-module, two utility functions encapsulating the ASAP calculator use from the hecss.util sub-module and, finally, the bulk crystal builder from the ase.build library.\n\nfrom hecss import HECSS\nfrom hecss.monitor import plot_stats\nfrom hecss.util import select_asap_model, create_asap_calculator\nfrom ase.build import bulk\n\n\n\nCrystal building\nTo build the structure of the crystal we are using the bulk method from ASE and provide the information defining the crystal (cubic 3C SiC structure in our case): * composition: ‘SiC’ * type of structure: ‘zincblende’ * size of the cell: a=4.38… * variant of the unit cell: cubic (instead of primitive) * size of the supercell: 3x3x3\n\nsc = (3,3,3)\ncryst = bulk('SiC', crystalstructure='zincblende',\n             a=4.38120844, cubic=True).repeat(sc)\n\n\n\nCalculator setup\nThe next step requires defining of the calculator used for evaluating energies and forces in the system. In our case it will be ASAP3 calculator. The hecss.util module provides two functions which simplify use of this calculator: * select_asap_model: automatically selects the model for the given composition (list of elements) * create_asap_calculator: creates calculator object These are fairly thin wrappers around ASE functions intended as a starting point for the user which is not familiar with ASE library and the calculator setup.\nThus, we first select the type of the potential (model) and then assign the created calculator object to the cryst object.\n\nmodel = select_asap_model('SiC')\ncryst.calc = create_asap_calculator(model)\n\n\n\nThe HECSS sampler object\nIn the next step we create object of the HECSS class, which encapsulates all of the configuration space functionality. By default, you can provide just the crystal object and either the calculator object (if it can be re-used) or the calculator generation function.\nIn the case of ASAP calculator we need to provide a generator, since, due to the peculiarities of the ASAP implementation of the ASE calculator which cannot be re-used when the sampler is re-executed. This is achieved with the second parameter with the lambda anonymous function. This construct is probably not required for all calculators (e.g. for VASP we can use just calculator object).\nThe last parameter (pbar) specifies that we want to have progress bar indicating the progress of the calculation.\n\nhecss = HECSS(cryst, lambda : create_asap_calculator(model), pbar=True)\n\n\n\nPrior distribution\nThe configuration space sampling starts with the generation of the prior energy distribution with the HECSS.sampe method. It generates a number (N here) of configurations with corresponding displacements, forces and energies targeted at some temperature (T here). The energy distribution of the sample is somewhat wider then the intended thermodynamic distribution described in the Background section. Nevertheless, we expect the distribution to be fairly close to the target (orange, dashed line), and the plot provided by the plot_stats confirms our expectation.\n\nT = 600\nN = 250\nsamples = hecss.sample(T,N)\nplot_stats(samples, T)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThermodynamic distribution\nThe second step in the configuration space sampling is a proper re-shaping of the sample to give it normal average energy distribution expected in the thermodynamic equilibrium. This is achieved by creating proper weighting of the samples generated in the previous step. This weighting is realised with the HECSS.generate method which, in turn, encapsulates distribution shaper implemented in make_sampling function from the hecss.optimize sub-module. See Optimize section for implementation details.\nThe final sampling is generated for the target temperature (T) and should fall close to the expected thermal equilibrium distribution - as the diagnostic plot below confirms.\n\ndistrib = hecss.generate(samples, T)\nplot_stats(distrib, T)\n\n\n\n\n\n\n\n\nAlternatively, if the precise temperature is not important, you can generate distribution around actual mean energy - optimising the effectiveness of the sampling.\n\ndistrib = hecss.generate(samples)\nplot_stats(distrib)",
    "crumbs": [
      "LAMMPS Tutorial"
    ]
  },
  {
    "objectID": "mh.html",
    "href": "mh.html",
    "title": "MH (Metropolis-Hastings)",
    "section": "",
    "text": "The implementation of the core functionality is centered around this generator function which yields samples from the thermal distribution at a given temperature. This is more flexible but also more advanced technique. For every-day use it is better to employ HECSS class which facilitates more traditional interface and usage patterns using this function under the hood.\n\n\nA general usage scheme is to run the sampler in the for loop as an iterator providing series of samples.\n\nN: number of requested samples,\ncryst : structure to be calculated,\ncalc : ASE calculator\nT: target temperature in Kelvin.\n\nLoop variables:\n\nn : sample number\ni : sample configuration index (may not change between samples)\nx : displacement vector\nf : forces\ne : potential energy\n\nThe minimal main loop should be structured like this:\nsampler = HECSS_Sampler(cryst, calc, T)\nfor n, i, x, f, e in sampler:\n    process_sample(n, i, x, f, e)\n    if n &gt; N :\n        break\nsampler.close()\nThis structure is well suited for the interactive use inside the notebook. It is possible in this setup to run few initial iterations to test if all works well and then continue the same loop by just increasing the N variable and re-running the above loop to continue the calculations.\nAlternatively, if you know that you need particular number of iterations you can use the N parameter of the sampler to produce a particular number of configurations:\nconfs = [sample for sample in HECSS_Sampler(cryst, calc, T, N=N)]\nprocess_samples(confs)\nThis setup is better suited to command-line work, but in this case you cannot continue the iterations after the loop finishes.\nThese are minimal examples. Look at VASP_Tutorial and LAMMPS_Tutorial for more elaborated examples.",
    "crumbs": [
      "MH (Metropolis-Hastings)"
    ]
  },
  {
    "objectID": "mh.html#hecss_sampler-generator-function",
    "href": "mh.html#hecss_sampler-generator-function",
    "title": "MH (Metropolis-Hastings)",
    "section": "",
    "text": "The implementation of the core functionality is centered around this generator function which yields samples from the thermal distribution at a given temperature. This is more flexible but also more advanced technique. For every-day use it is better to employ HECSS class which facilitates more traditional interface and usage patterns using this function under the hood.\n\n\nA general usage scheme is to run the sampler in the for loop as an iterator providing series of samples.\n\nN: number of requested samples,\ncryst : structure to be calculated,\ncalc : ASE calculator\nT: target temperature in Kelvin.\n\nLoop variables:\n\nn : sample number\ni : sample configuration index (may not change between samples)\nx : displacement vector\nf : forces\ne : potential energy\n\nThe minimal main loop should be structured like this:\nsampler = HECSS_Sampler(cryst, calc, T)\nfor n, i, x, f, e in sampler:\n    process_sample(n, i, x, f, e)\n    if n &gt; N :\n        break\nsampler.close()\nThis structure is well suited for the interactive use inside the notebook. It is possible in this setup to run few initial iterations to test if all works well and then continue the same loop by just increasing the N variable and re-running the above loop to continue the calculations.\nAlternatively, if you know that you need particular number of iterations you can use the N parameter of the sampler to produce a particular number of configurations:\nconfs = [sample for sample in HECSS_Sampler(cryst, calc, T, N=N)]\nprocess_samples(confs)\nThis setup is better suited to command-line work, but in this case you cannot continue the iterations after the loop finishes.\nThese are minimal examples. Look at VASP_Tutorial and LAMMPS_Tutorial for more elaborated examples.",
    "crumbs": [
      "MH (Metropolis-Hastings)"
    ]
  },
  {
    "objectID": "mh.html#hecss-class",
    "href": "mh.html#hecss-class",
    "title": "MH (Metropolis-Hastings)",
    "section": "HECSS class",
    "text": "HECSS class\nStandard interface to the HECSS library. This class encapsulates the actual sampler implemented in the HECSS_Sampler generator funtion and provides main functionality of the library through the generate method.\n\nUsage\nAfter creating HECSS object for the structure, calculator and temperature you call the generate method to obtain a list of samples of a given length.\n\nCubic Silica Carbide (3C-SiC)\n\nfrom ase.build import bulk\nfrom ase.spacegroup import crystal\nfrom hecss.monitor import plot_stats, plot_virial_stat, plot_xs_stat\nfrom hecss.monitor import plot_acceptance_history, plot_dofmu_stat\nfrom hecss.util import select_asap_model, create_asap_calculator\n\n\n# Local copy of model from OpenKIM-models from 2019\n# model = 'data/Tersoff_LAMMPS_ErhartAlbe_2005_SiC__MO_903987585848_003'\n# Model form 2019 OpenKIM-models package\n# model = 'Tersoff_LAMMPS_ErhartAlbe_2005_SiC__MO_903987585848_003'\n# Model form 2021 OpenKIM-models package\n# model = 'Tersoff_LAMMPS_ErhartAlbe_2005_SiC__MO_903987585848_004'\n# model = 'Tersoff_LAMMPS_ErhartAlbe_2005SiII_SiC__MO_408791041969_003'\n# model = 'MEAM_LAMMPS_KangEunJun_2014_SiC__MO_477506997611_000'\n\nmodel = select_asap_model('SiC')\nprint(f'Using potential model: {model}')\n\nsys_size = '1x1x1'\nsys_size = '2x2x2'\nsys_size = '3x3x3'\nsys_size = '4x4x4'\nsys_size = '5x5x5'\nsc = [int(v) for v in sys_size.split('x')]\ncryst = bulk('SiC', crystalstructure='zincblende',\n                 a=4.38120844, cubic=True).repeat(tuple(sc))\ncryst.calc = create_asap_calculator(model)\n\nUsing potential model: MEAM_LAMMPS_KangEunJun_2014_SiC__MO_477506997611_000\n\n\n\nT = 600\nxsl = []\ndofmu = []\nxi=1\nchi=0.66\nchi=1\nsampler = HECSS_MH(cryst, create_asap_calculator(model), \n                T, delta_sample=0.01, width=1,\n                dofmu_list=dofmu, xscale_list=xsl, xi=xi, chi=chi, pbar=True)\n\n\n\n\n\nN = 1_000\nsamples = sampler.generate(N)\nplot_stats(samples, T, sqrN=True)\n\n/home/jochym/.conda/envs/dev/lib/python3.11/site-packages/spglib/spglib.py:115: DeprecationWarning: dict interface (SpglibDataset['mapping_to_primitive']) is deprecated.Use attribute interface ({self.__class__.__name__}.{key}) instead\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(10,4))\nfor n, el in enumerate(set(cryst.get_chemical_symbols())):\n    elmap = np.array(cryst.get_chemical_symbols()) == el\n    plt.plot(np.array(xsl)[:,elmap,:].mean(-2), label=el)\n# plt.legend()\n\n\n\n\n\n\n\n\n\n\nOlivine in the cubic spinel structure (gamma phase)\n\nomodel = select_asap_model('Universal')\nprint(f'Using potential model: {omodel}')\n\noliv = ase.io.read('data/spinel.POSCAR')\noliv.calc = create_asap_calculator(omodel)\nprint(f'Space group: {spglib.get_spacegroup(get_cell_data(oliv))}')\n\nUsing potential model: LJ_ElliottAkerson_2015_Universal__MO_959249795837_003\nSpace group: Fd-3m (227)\n\n\n\nprint(f'Max. stress: {np.abs(oliv.get_stress()[:3]).max()/un.GPa:.3f} GPa')\nprint(f'Max. force : {np.abs(oliv.get_forces()).max():.3f} eV/A')\n\nMax. stress: 0.881 GPa\nMax. force : 0.002 eV/A\n\n\n\nT = 600\ndofmu = []\nxsl = []\nxi = 1\nchi = 1\nosampler = HECSS_MH(oliv, create_asap_calculator(omodel), \n                 T, delta_sample=0.01, width=0.7,\n                 xi=xi, chi=chi,\n                 dofmu_list=dofmu, xscale_list=xsl)\nN = 5_00\nosamples = osampler.generate(N)\nplot_stats(osamples, T, sqrN=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\nContinuation of the earlier calculation",
    "crumbs": [
      "MH (Metropolis-Hastings)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HECSS",
    "section": "",
    "text": "HECSS is a Monte-Carlo, configuration space sampler using sample weighting algorithm for probability distribution sampling. It provides an alternative way to create representations of systems at thermal equilibrium without running a very expensive molecular dynamics simulation. The theoretical foundation of the code are presented in the section Background in the Documentation. More detailed examples are included in the LAMMPS and VASP tutorials.\nYou can try HECSS on binder:",
    "crumbs": [
      "HECSS"
    ]
  },
  {
    "objectID": "index.html#a-very-short-example",
    "href": "index.html#a-very-short-example",
    "title": "HECSS",
    "section": "A very short example",
    "text": "A very short example\nMinimal example using LAMMPS potential from the asap3 package and OpenKIM database. Here we will sample the thermodynamic distribution of 3C-SiC crystal at 300K. We start by importing required modules, define the crystal and energy/forces calculator, run the sampler and finally plot the energy distribution.\n\nfrom hecss import HECSS\nfrom hecss.util import select_asap_model, create_asap_calculator\nfrom hecss.monitor import plot_stats\nfrom ase.build import bulk\n\nThen we define the crystal and interaction model used in the calculation. In this case we use 3x3x3 supercell of the SiC crystal in zincblende structure and describe the interaction using LAMMPS potential from the OpenKIM database and ASAP3 implementation of the calculator.\n\nmodel = select_asap_model('SiC')\ncryst = bulk('SiC', crystalstructure='zincblende', \n             a=4.38120844, cubic=True).repeat((3,3,3))\ncryst.calc = create_asap_calculator(model)\n\nThen we define the sampler parameters (N – number of samples, T – temperature) and run it. The parameter with the lambda anonymous function is required in this case, due to the peculiarities of the ASAP implementation of the ASE calculator which cannot be re-used when the sampler is re-executed. This construct is probably not required for other calculators.\n\nT = 300\nN = 100\nhecss = HECSS(cryst, lambda : create_asap_calculator(model))\nsamples = hecss.sample(T, N)\ndistrib = hecss.generate(samples, T)\n\nAnd finally we plot the histogram of the resulting energy distribution which corresponds to the thermal equilibrium distribution.\n\nplot_stats(distrib, T, sqrN=True)",
    "crumbs": [
      "HECSS"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "HECSS",
    "section": "Install",
    "text": "Install\nThe HECSS package is available on pypi and conda-forge additionally the package is present also in my personal anaconda channel (jochym). Installation is simple, but requires a number of other packages to be installed as well. Package managers handle these dependencies automatically.\n\nInstall with pip\nIt is advisable to install in a dedicated virtual environment e.g.:\npython3 -m venv venv\n. venv/bin/activate\nthen install with pip:\npip install hecss\n\n\nInstall with conda\nAlso installation with conda should be performed for dedicated or some other non-base environment. To create dedicated environment you can invoke conda create:\nconda create -n hecss -c conda-forge hecss\nor you can install in some working environment venv:\nconda install -n venv -c conda-forge hecss\n\n\nExample data archive\nThe example subdirectory from the source may be downloaded directly from the source repository: hecss-examples.zip\n\n\nThe source code\nThe source is published at the Gitlab hecss repository. You can access it with git (recommended, particularly if you want to contribute to the development):\ngit clone https://gitlab.com/jochym/hecss.git\nor you can download the whole distribution as a zip archive: hecss.zip",
    "crumbs": [
      "HECSS"
    ]
  },
  {
    "objectID": "vasp_tutorial.html",
    "href": "vasp_tutorial.html",
    "title": "VASP Tutorial",
    "section": "",
    "text": "First we need to setup the environment by importing required tools from ASE, stadlib tqdm and hecss libraries.\n\n# Import VASP calculator and unit modules\nfrom ase.calculators.vasp import Vasp\nfrom ase import units as un\nfrom os.path import isfile\nimport os\n\n# The sample generator, monitoring display and dfset writer\nfrom hecss import HECSS\nfrom hecss.util import write_dfset\nfrom hecss.monitor import plot_stats\n\n# Numerical and plotting routines\nimport numpy as np\nfrom matplotlib import pyplot as plt",
    "crumbs": [
      "VASP Tutorial"
    ]
  },
  {
    "objectID": "vasp_tutorial.html#setup",
    "href": "vasp_tutorial.html#setup",
    "title": "VASP Tutorial",
    "section": "",
    "text": "First we need to setup the environment by importing required tools from ASE, stadlib tqdm and hecss libraries.\n\n# Import VASP calculator and unit modules\nfrom ase.calculators.vasp import Vasp\nfrom ase import units as un\nfrom os.path import isfile\nimport os\n\n# The sample generator, monitoring display and dfset writer\nfrom hecss import HECSS\nfrom hecss.util import write_dfset\nfrom hecss.monitor import plot_stats\n\n# Numerical and plotting routines\nimport numpy as np\nfrom matplotlib import pyplot as plt",
    "crumbs": [
      "VASP Tutorial"
    ]
  },
  {
    "objectID": "vasp_tutorial.html#system-setup",
    "href": "vasp_tutorial.html#system-setup",
    "title": "VASP Tutorial",
    "section": "System setup",
    "text": "System setup\nYou can run more realistic test using 2x2x2 (or even larger) supercell. The results generated by such calculation are included in the example/VASP_3C-SiC_calculated directory in the source tree. You can run post-processing on these results and use them as a reference. By changing the value of the supercell variable:\nsupercell = '2x2x2'\nyou can run a more realistic calculations. If you want to run your own calulation be prepared for some substantial computational resources required for such a job. A single 2x2x2 job takes 2-5 minutes on the 64-core computing node. Better test first with single unit cell setup. For this tutorial we will run with very small system - just a single unit cell of 3C-SiC crystal.\n\n# Quick test using conventional unit cell\nsupercell = '1x1x1'\n\n\n# Slow more realistic test\nsupercell = '2x2x2'\n\n\n# Directory in which our project resides\nbase_dir = f'example/VASP_3C-SiC/{supercell}/'",
    "crumbs": [
      "VASP Tutorial"
    ]
  },
  {
    "objectID": "vasp_tutorial.html#calculator-setup",
    "href": "vasp_tutorial.html#calculator-setup",
    "title": "VASP Tutorial",
    "section": "Calculator setup",
    "text": "Calculator setup\nYou need to configure your own environment for VASP. The run-calc script located in the root directory is an example from my own system. You need to modify it to fit your system. Running run-calc in a given directory should submit a VASP job to your cluster and wait for it to end. Example of such job script from my system (small cluster with SLURM job menager) is included in example/scripts directory.\n\n# Read the structure (previously calculated unit(super) cell)\n# The command argument is specific to the cluster setup\ncalc = Vasp(label='cryst', directory=f'{base_dir}/sc_{supercell}/', restart=True)\n\n# This just makes a copy of atoms object\n# Do not generate supercell here - your atom ordering will be wrong!\ncryst = calc.atoms.repeat(1)\n\nIf you have magmoms in your system you need to use following temporary fix for a bug in magmom handling in Vasp2 calculator:\nif 'magmom' in calc.list_float_params:\n    calc.list_float_params['magmom'] = cryst.get_initial_magnetic_moments()\nJust copy the above code to a new cell here and execute it.\n\n# Setup the calculator - single point energy calculation\n# The details will change here from case to case\n# We are using run-vasp from the current directory!\ncalc.set(directory=f'TMP/calc_{supercell}/sc')\ncalc.set(command=f'{os.getcwd()}/run-calc.sh \"3C-SiC-{supercell}\"')\ncalc.set(nsw=0)\ncryst.calc = calc",
    "crumbs": [
      "VASP Tutorial"
    ]
  },
  {
    "objectID": "vasp_tutorial.html#system-check",
    "href": "vasp_tutorial.html#system-check",
    "title": "VASP Tutorial",
    "section": "System check",
    "text": "System check\nYou should probably check the calculator setup and the stress tensor of the supercell to make sure it is in equilibrium before running long sequence of DFT calculations. Here is an example:\n\nprint('Stress tensor: ', end='')\nfor ss in calc.get_stress()/un.GPa:\n    print(f'{ss:.3f}', end=' ')\nprint('GPa')\n\nStress tensor: 0.017 0.017 0.017 0.000 0.000 0.000 GPa",
    "crumbs": [
      "VASP Tutorial"
    ]
  },
  {
    "objectID": "vasp_tutorial.html#running-hecss",
    "href": "vasp_tutorial.html#running-hecss",
    "title": "VASP Tutorial",
    "section": "Running HECSS",
    "text": "Running HECSS\nThere are multiple ways you can use HECSS to generate samples – depending from the stage your project is, your familiarity with python language and sophistication required by your project.\nYou would probably start with more exploratory setup when you start the project and do not know yet the behaviour of the system. It is best to start with small structure, small initial number of samples and code structure which allows for iterating by returning to the same calculation to generate more samples or breaking the loop which goes wrong. This type of calculation may be well served by the code like the following example:\n\n# Space for results\nxsl = []\ncalc_dir = f'TMP/calc_{supercell}'\n\n\n# Build the sampler\nhecss = HECSS(cryst, calc, \n              directory=f'{calc_dir}',\n              w_search = True,\n              pbar=True,\n              # reuse_base=f'{base_dir}/calc/' # Use if you want to reuse the base calc\n              )\n\n\nm, s, xscl = hecss.estimate_width_scale(10, nwork=0)\nwm = np.array(hecss._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplt.plot(wm[1], y, '.');\nx = np.linspace(0, 1.05*wm[1].max(), 2)\nfit = np.polyfit(wm[1], y, 1)\nplt.plot(x, np.polyval(fit, x), ':', label=f'{fit[1]:.4g} {fit[0]:+.4g} T')\nplt.axhline(m, ls='--', label=f'{m:.4g}±{s:.4g}')\nplt.axhspan(m-s, m+s, alpha=0.3)\nplt.ylim(m-4*s, m+4*s)\nplt.xlabel('Target temperature (K)')\nplt.ylabel('width scale ($\\\\AA/\\\\sqrt{K}$)')\nplt.legend();\n\n\n\n\n\n\n\n\n\n\n\n\n# Temperature (K)\nT = 300\n\n\n# Desired number of samples.\n# Here 4 is minimal in 3C-SiC \n# to get somewhat decent phonons \n# with 10 Bohr cutoff.\nN = 4\n\n\nsamples = hecss.sample(T, N)\n\n\n\n\n\nplot_stats(samples, T)\ndistrib = hecss.generate(samples, T)\nplot_stats(distrib, T, sqrN=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter the first run you can increase the limit (N) and return to the same loop (the state of the sampler is preserved) to generate more samples. This cell can be executed multiple times to collect enough samples for further analysis. You can also monitor the progress by providing sentinel argument to the generate method. Here is a simple monitoring function showing an updated histogram and position of the last sample (as dotted line)\n\ndef show_stats(s, sl, col=None, Temp=None):\n    from matplotlib import pyplot as plt\n    from IPython.display import clear_output\n    from hecss.optimize import make_sampling\n    plot_stats(make_sampling(sl if col is None else col + sl, Temp), \n               Temp, show=False)\n    plt.axvline(s[-1], ls=':', label='Last sample')\n    plt.legend()\n    plt.show()\n    clear_output(wait=True)\n    # Important! Return False to keep iteration going\n    return False\n\n\n# Need more samples. Increase N and get more samples.\nN = 10\nsamples += hecss.sample(T, N, sentinel=show_stats, \n                              sentinel_args={'col':samples, 'Temp':T})\nplot_stats(hecss.generate(samples, T), T, sqrN=True)\n\n\n\n\n\n\n\n\n\nsamples += hecss.sample(T, N, sentinel=show_stats, \n                              sentinel_args={'col':samples, 'Temp':T})\n\n\n\n\n\n\n\n\n\n# Verify if we really got the same picture\nplot_stats(hecss.generate(samples, T), T, sqrN=True)\n\n\n\n\n\n\n\n\n\nfor c in samples:\n    write_dfset(f'{calc_dir}/DFSET_T={T}K.dat', c)\n\nWhen you are at production stage of your project and you know exactly what you want and how to get it the more compact style of code may be better. Though, it is less elastic and forgiving of mistakes. Here is a similar sampling run at T=600 K.\n\nT=600\nconfs_600 = hecss.sample(T, 50)\nplot_stats(hecss.generate(confs_600, T), T, sqrN=True)\n\n\n\n\n\n\n\n\n\n\n\n\nfor c in confs_600:\n    write_dfset(f'{calc_dir}/DFSET_T={T}K.dat', c)\n\n\nhecss.generate(confs_600, T, debug=True);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nc_1000 = hecss.sample(1000, 50)\n\n\n\n\n\nT_1000 = np.array([s[-1] for s in c_1000]).mean()\n\n\ns_1000 = hecss.generate(c_1000, 2*T_1000/un.kB/3, border=True, debug=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor c in s_1000:\n    write_dfset(f'{calc_dir}/DFSET_T={1000}K.dat', c)",
    "crumbs": [
      "VASP Tutorial"
    ]
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "Background",
    "section": "",
    "text": "To reproduce the thermal equilibrium in the system, independent configurations of displacements consistent with a desired non-zero temperature should be selected. Having any initial approximations for the lattice dynamics of the system (e.g. standard harmonic approach) one can estimate temperature-dependent atomic mean-square-displacements (MSD) using a small set of force-displacement relations. Using these MSD data as a first approximation, the atomic displacements with normal distribution around equilibrium positions can be easily generated. There is, however, a subtle issue around displacements generated this way – they are uncorrelated between atoms, while in reality atomic displacements are correlated at least for their close neighbours. For example, it is easy to see that a simultaneous out-of-phase movement of neighbouring atoms towards or away from each other will generate larger changes in energy than a synchronous in-phase movement of the same atoms. The former configuration should be represented with lower probability than the later, instead of equal probability present in the above simplistic scheme. Thus, while the static configurations generation may be a correct direction in general, such a naive approach is not sufficient.\nOne can see that some additional mechanism is required to adjust probability distribution of generated samples in order to accurately reproduce configurations drawn from thermodynamic equilibrium ensemble. Classical statistical mechanics points to such a scheme for selection of configurations representing a system in thermal equilibrium.\nThe general form of the equipartition theorem says that a generalised virial for any phase space coordinate (i.e. generalised coordinate or momentum) is proportional to temperature when it is averaged over the whole ensemble:\n\\[\n\\left\\langle x_m \\frac{\\partial H}{\\partial x_n}\\right\\rangle = \\delta_{mn}k_B T\n\\]\nIf we assume ergodicity of the system, the ensemble average may be replaced with time average. For momenta this leads to the average kinetic energy per degree of freedom being equal to \\(k_B T/2\\) and provides the kinetic definition of temperature. However, the relation holds also for derivatives of Hamiltonian with respect to positions. Considering relation for some atomic displacement \\(q\\) from the equilibrium configuration, and assuming the potential energy depends only on position, we can write position-dependent part of the Hamiltonian (i.e the potential energy \\(E_p(q)\\)) as a Taylor’s expansion with respect to the atomic displacement \\(q\\) from the equilibrium configuration:\n\\[\nE_p(q) = \\sum_{n=2}^{\\infty} C_n q^n,\n\\]\nwhere the expansion coefficients \\(C_n\\) are, in general, functions of all remaining coordinates (displacements). The equipartition theorem now takes the form:\n\\[\nk_B T = \\left\\langle q \\sum_{n=2}^{\\infty} n C_n q^{n-1} \\right\\rangle = \\sum\\limits_{n=2}^\\infty n C_n \\left\\langle q^n \\right\\rangle\n\\]\nand if we write \\(n\\) as \\((n-2)+2\\) and divide both sides by \\(2\\) we get:\n\\[\n\\left\\langle E_p(q)\\right\\rangle =\n%\\left\\langle \\sum_{n=2}^{\\infty} C_n q^n \\right\\rangle =\n\\frac{k_B T}{2} -\n    \\sum\\limits_{n=3}^\\infty \\frac{n-2}{2}C_n \\left\\langle q^n \\right\\rangle,\n\\]\nwhich is similar to the kinetic energy counterpart except for an additional term generated by the anharmonic part of the potential and defined by the third and higher central moments of the probability distribution of the displacements. If we can assume that the second term is small in comparison with \\(k_B T\\), we get a formula for the average potential energy of the system. Note that for harmonic systems the second part vanishes. For anharmonic systems omission of higher terms will provide first-order approximation of the mean potential energy. Only experience can tell us how good this approximation is and how wide its applicability range is. However, one should note that substantial higher-order terms are present only in parts of the formula connected with strongly anharmonic modes. Furthermore, for every atom in centro-symmetric position all odd-power moments vanish and the first non-zero moment is the fourth one. Finally, the formula for the potential energy of the whole system contains similar terms for all modes. Judging by extremely high efficiency of harmonic approximation for crystal lattice dynamics, we can expect that this averaging will make proposed approximation effective for a wide range of systems.\nTo sum up, MD provides a representation of the system with the properly distributed kinetic energy. For a single particle it is a Maxwell-Boltzmann distribution. By virtue of the central limit theorem (CLT), if we increase the number of particles we will approach at infinity (i.e. in the thermodynamical limit) a Gaussian distribution with the same average (the same mean) and the variance which is scaled as inverse number of particles. As we can see for kinetic energy the relation is very simple whereas for the potential energy we have a quantity approximately close to temperature if the system is not too far from a harmonic one. Nevertheless, we do not know, in general, the form of the distribution of the potential energy. That constitutes substantial difficulty, which fortunately can be overcome by application of the CLT to calculate distribution of potential energy.\nThe CLT states that for any reasonable probability distribution, the distribution of the mean of the sample of the independent random variable drawn from it, tends to the normal distribution with the same mean and variance scaled by the square root of the number of samples. The reasonable class is fairly broad here, including many physically interesting cases by virtue of requiring only a finite variance and a well-defined mean. Obviously, this excludes important case of systems close to phase transitions with divergent specific heat (i.e. divergent energy variance, e.g. melting). Thus, for potential energy per degree of freedom we can expect the probability distribution to asymptotically converge to the normal distribution: \\[\n    \\sqrt{3N}\\left(\\frac{1}{N} \\sum_i E_i -\\langle E\\rangle \\right) \\xrightarrow{d}\\mathcal{N}(0, \\sigma).\n\\tag{1}\\]\nAs shown above, one can approximate the \\(\\langle E \\rangle\\) with the first term of the previous equation and the only unknown parameter in this formula is the variance of the distribution. Note that above expression is independent from the particular shape of the potential energy probability distribution for the single degree of freedom except of its mean \\(\\langle E \\rangle\\) and variance \\(\\sigma\\).\nHowever, we need to consider that the CLT is true asymptotically. At this point we need to decide if this relation has any practical use for finite, and preferably not too large, \\(N\\)? The common wisdom in statistical community states that for \\(N \\gtrapprox 50\\) the distribution of the average is practically indistinguishable from the true normal distribution, and even for smaller \\(N\\) if the starting distribution is not too wild the convergence is usually very quick.",
    "crumbs": [
      "Background"
    ]
  },
  {
    "objectID": "background.html#general-idea-of-hecss",
    "href": "background.html#general-idea-of-hecss",
    "title": "Background",
    "section": "",
    "text": "To reproduce the thermal equilibrium in the system, independent configurations of displacements consistent with a desired non-zero temperature should be selected. Having any initial approximations for the lattice dynamics of the system (e.g. standard harmonic approach) one can estimate temperature-dependent atomic mean-square-displacements (MSD) using a small set of force-displacement relations. Using these MSD data as a first approximation, the atomic displacements with normal distribution around equilibrium positions can be easily generated. There is, however, a subtle issue around displacements generated this way – they are uncorrelated between atoms, while in reality atomic displacements are correlated at least for their close neighbours. For example, it is easy to see that a simultaneous out-of-phase movement of neighbouring atoms towards or away from each other will generate larger changes in energy than a synchronous in-phase movement of the same atoms. The former configuration should be represented with lower probability than the later, instead of equal probability present in the above simplistic scheme. Thus, while the static configurations generation may be a correct direction in general, such a naive approach is not sufficient.\nOne can see that some additional mechanism is required to adjust probability distribution of generated samples in order to accurately reproduce configurations drawn from thermodynamic equilibrium ensemble. Classical statistical mechanics points to such a scheme for selection of configurations representing a system in thermal equilibrium.\nThe general form of the equipartition theorem says that a generalised virial for any phase space coordinate (i.e. generalised coordinate or momentum) is proportional to temperature when it is averaged over the whole ensemble:\n\\[\n\\left\\langle x_m \\frac{\\partial H}{\\partial x_n}\\right\\rangle = \\delta_{mn}k_B T\n\\]\nIf we assume ergodicity of the system, the ensemble average may be replaced with time average. For momenta this leads to the average kinetic energy per degree of freedom being equal to \\(k_B T/2\\) and provides the kinetic definition of temperature. However, the relation holds also for derivatives of Hamiltonian with respect to positions. Considering relation for some atomic displacement \\(q\\) from the equilibrium configuration, and assuming the potential energy depends only on position, we can write position-dependent part of the Hamiltonian (i.e the potential energy \\(E_p(q)\\)) as a Taylor’s expansion with respect to the atomic displacement \\(q\\) from the equilibrium configuration:\n\\[\nE_p(q) = \\sum_{n=2}^{\\infty} C_n q^n,\n\\]\nwhere the expansion coefficients \\(C_n\\) are, in general, functions of all remaining coordinates (displacements). The equipartition theorem now takes the form:\n\\[\nk_B T = \\left\\langle q \\sum_{n=2}^{\\infty} n C_n q^{n-1} \\right\\rangle = \\sum\\limits_{n=2}^\\infty n C_n \\left\\langle q^n \\right\\rangle\n\\]\nand if we write \\(n\\) as \\((n-2)+2\\) and divide both sides by \\(2\\) we get:\n\\[\n\\left\\langle E_p(q)\\right\\rangle =\n%\\left\\langle \\sum_{n=2}^{\\infty} C_n q^n \\right\\rangle =\n\\frac{k_B T}{2} -\n    \\sum\\limits_{n=3}^\\infty \\frac{n-2}{2}C_n \\left\\langle q^n \\right\\rangle,\n\\]\nwhich is similar to the kinetic energy counterpart except for an additional term generated by the anharmonic part of the potential and defined by the third and higher central moments of the probability distribution of the displacements. If we can assume that the second term is small in comparison with \\(k_B T\\), we get a formula for the average potential energy of the system. Note that for harmonic systems the second part vanishes. For anharmonic systems omission of higher terms will provide first-order approximation of the mean potential energy. Only experience can tell us how good this approximation is and how wide its applicability range is. However, one should note that substantial higher-order terms are present only in parts of the formula connected with strongly anharmonic modes. Furthermore, for every atom in centro-symmetric position all odd-power moments vanish and the first non-zero moment is the fourth one. Finally, the formula for the potential energy of the whole system contains similar terms for all modes. Judging by extremely high efficiency of harmonic approximation for crystal lattice dynamics, we can expect that this averaging will make proposed approximation effective for a wide range of systems.\nTo sum up, MD provides a representation of the system with the properly distributed kinetic energy. For a single particle it is a Maxwell-Boltzmann distribution. By virtue of the central limit theorem (CLT), if we increase the number of particles we will approach at infinity (i.e. in the thermodynamical limit) a Gaussian distribution with the same average (the same mean) and the variance which is scaled as inverse number of particles. As we can see for kinetic energy the relation is very simple whereas for the potential energy we have a quantity approximately close to temperature if the system is not too far from a harmonic one. Nevertheless, we do not know, in general, the form of the distribution of the potential energy. That constitutes substantial difficulty, which fortunately can be overcome by application of the CLT to calculate distribution of potential energy.\nThe CLT states that for any reasonable probability distribution, the distribution of the mean of the sample of the independent random variable drawn from it, tends to the normal distribution with the same mean and variance scaled by the square root of the number of samples. The reasonable class is fairly broad here, including many physically interesting cases by virtue of requiring only a finite variance and a well-defined mean. Obviously, this excludes important case of systems close to phase transitions with divergent specific heat (i.e. divergent energy variance, e.g. melting). Thus, for potential energy per degree of freedom we can expect the probability distribution to asymptotically converge to the normal distribution: \\[\n    \\sqrt{3N}\\left(\\frac{1}{N} \\sum_i E_i -\\langle E\\rangle \\right) \\xrightarrow{d}\\mathcal{N}(0, \\sigma).\n\\tag{1}\\]\nAs shown above, one can approximate the \\(\\langle E \\rangle\\) with the first term of the previous equation and the only unknown parameter in this formula is the variance of the distribution. Note that above expression is independent from the particular shape of the potential energy probability distribution for the single degree of freedom except of its mean \\(\\langle E \\rangle\\) and variance \\(\\sigma\\).\nHowever, we need to consider that the CLT is true asymptotically. At this point we need to decide if this relation has any practical use for finite, and preferably not too large, \\(N\\)? The common wisdom in statistical community states that for \\(N \\gtrapprox 50\\) the distribution of the average is practically indistinguishable from the true normal distribution, and even for smaller \\(N\\) if the starting distribution is not too wild the convergence is usually very quick.",
    "crumbs": [
      "Background"
    ]
  },
  {
    "objectID": "background.html#atomic-displacement-probability-distribution",
    "href": "background.html#atomic-displacement-probability-distribution",
    "title": "Background",
    "section": "Atomic displacement probability distribution",
    "text": "Atomic displacement probability distribution\nThe individual atomic displacements need to be generated from some probability distribution. The normal distribution of energy does not imply the same distribution of positions of individual atoms. The average distribution of large number of atoms tends to normal distribution, thanks to the CLT - in the same way as average energy distribution described above. However, there is no such rule for individual atomic displacements. These displacements may be governed by the distributions, which are very far from the normal distribution. In fact, the probability density \\(p(u|A)\\) of the displacement \\(u\\) of the individual harmonic oscillator with amplitude \\(A\\) is the \\(\\arcsin\\) distribution: \\[\np(u|A) = \\frac{1}{\\pi\\sqrt{A^2 - u^2}},\n\\] which is shown in Figure 1.\n\n\nCode\nA = 1\nu = np.linspace(-A, A, 301)[1:-1]\nplt.plot(u, stats.arcsine.pdf(u, -A, 2*A))\nplt.axvline(-A, ls=':', lw=1, color='k');\nplt.axvline(A, ls=':', lw=1, color='k');\nplt.xlabel('Displacement')\nplt.ylabel('Probability density');\n\n\n\n\n\n\n\n\nFigure 1: Probability distribution of the displacement of the harmonic oscillator.\n\n\n\n\n\nThe distribution from the Figure 1 is obviously very far from the normal distribution. However, this is distribution for a single, isolated oscillator. Atoms in the crystal are a part of the thermodynamic ensemble and exchange energy with other atoms in the crystal. Thus, the amplitude \\(A\\) of each oscillator in the crystal is itself a random variable directly connected with the temperature of the crystal. As we know from the statistical mechanics, the probability density of energy in the thermodynamic ensemble is proportional to the Boltzmann factor:\n\\[\np(E) = \\frac{1}{\\cal{N}}\\exp\\left({-\\frac{E}{k_B T}}\\right)\n\\]\nIf we assume the potential energy to be approximately quadratic: \\[\nE \\approx \\frac{\\alpha}{2} u^2\n\\] the probability density of amplitude \\(A\\) in the crystal can be calculated from the energy distribution: \\[\np(E) dE = \\frac{1}{\\cal{N}}\\exp\\left({-\\frac{E}{k_B T}}\\right) dE =\n\\left| \\substack{\\textstyle\n    E = \\frac{\\alpha}{2} A^2 \\\\\n    dE = \\alpha A dA\n}\\right| = \\alpha A\\exp\\left(-\\frac{\\alpha A^2}{2 k T}\\right) dA = p(A) dA,\n\\] which is a \\(\\chi\\) distribution with two degrees of freedom also known as Rayleigh distribution. The Figure 2 illustrates the shape of this distribution.\n\n\nCode\nu = np.linspace(0, 4, 301)\nplt.plot(u, stats.rayleigh.pdf(u))\nplt.xlabel('Amplitude')\nplt.ylabel('Probability density');\n\n\n\n\n\n\n\n\nFigure 2: Probability distribution of the amplitude of the harmonic oscillator in the thermodynamic ensemble.\n\n\n\n\n\nThe total probability \\({\\cal P}(u)\\) of the displacement \\(u\\) of a single atom in the crystal is a sum of all distributions which are compatible with this displacement: \\[\n{\\cal P}(u) = \\int\\limits_u^\\infty p(u|A) p(A) dA =\n\\frac{1}{\\cal{N}}\\int\\limits_u^\\infty\n     \\frac{\\alpha A \\exp\\left(-\\frac{\\alpha A^2}{2 k T}\\right)}\n             {\\pi\\sqrt{A^2 - u^2}}  dA =\n\\frac{1}{\\cal{N}}\\sqrt{\\frac{\\alpha k T}{2 \\pi}}\n        \\exp\\left(-\\frac{\\alpha u^2}{2 k T}\\right),\n\\] which is proportional to the normal distribution.\nThe above derivation justifies use of the normal distribution in the displacement generation in HECSS sampler. Note, however, that the deviations from the quadratic shape of the energy surface may skew the \\({\\cal P}(u)\\) distribution. This is mitigated by the fact that the \\({\\cal P}(u)\\) is used for generation of the prior distribution, which is later morphed into the target distribution by the later stages of the HECSS procedure. The prior distribution should be just close to the target. Small discrepancies have only minor impact on the effectiveness of the process.",
    "crumbs": [
      "Background"
    ]
  },
  {
    "objectID": "background.html#equilibration-between-degrees-of-freedom",
    "href": "background.html#equilibration-between-degrees-of-freedom",
    "title": "Background",
    "section": "Equilibration between degrees of freedom",
    "text": "Equilibration between degrees of freedom\nThe procedure described above leads to the statistical ensemble with correctly distributed total energy. This is equivalent to the correct temperature of the system but not necessarily to the thermodynamic equilibrium, since different degrees of freedom (DOF) may carry different portion of the total energy. To make the temperature of each DOF the same, the sampling procedure employs a similar scheme to each set of symmetry-connected DOFs as is used for total energy - making each averaged virial the same for these DOFs. This procedure is particularly effective for systems with many DOFs connected by symmetry (e.g. regular crystals). It seems less effective for systems with very low symmetry (e.g. decorated surfaces or molecules). The principle still works, only the large number of DOFs makes for large statistical fluctuations for each DOF - due to the low statistics and less effective averaging.\nIn detail, at each step the virial for each DOF is calculated with relation to temperature:\n\\[\n\\mu = \\frac{\\left|f x \\right|}{k_B T}\n\\]\nwhere \\(f, x\\) are newly generated displacements and forces for each DOF. This quantity gets averaged over all images of the particular DOF in the supercell/structure: $= _{DOF} $. The amplitude correction is calculated using sigmoid function \\(g(x)=1/(1+\\exp(-x))\\) similar to the one used for the total energy step. The value of the computed function is used to multiply the actual amplitude correction factors \\(s_n\\) to get the factor for the next step in the procedure (at the start \\(s_0=1\\)): \\[\ns_{n+1} = s_{n} \\left( 1 - 2 \\delta_{eq}\n                \\left( g\n                     \\left( \\frac{\\sqrt{\\bar\\mu}-1}{\\sigma_{eq}}\n                     \\right) - 0.5\n                \\right)\n           \\right)\n\\]\nwhere \\(\\delta_{eq}, \\sigma_{eq}\\) define the maximum size of the correction and the half-width of the approximately linear part of the \\(g\\) function, respectively. The calculated values are further normalised in the following way: \\[\n    s_{n+1} \\leftarrow \\frac{s_{n+1}}{\\sqrt{\\langle s_{n+1}^2 \\rangle_{DOF}}},\n\\] to keep the total energy unchanged. We denote here \\(\\langle \\rangle_{DOF}\\) the mean calculated over all images of the same DOF in the system. Finally \\(s_{n+1}\\) are mixed with the \\(s_n\\) values from the previous step, with the mixing factor \\(\\chi\\in[0,1]\\) (by default \\(\\chi=1\\), i.e. no mixing): \\[\n    s_{n+1} \\leftarrow \\chi s_{n+1} + (\\chi - 1)s_n.\n\\] These coefficients are calculated for each DOF separately and used in the next step to scale generated displacements of all images of the particular DOF.",
    "crumbs": [
      "Background"
    ]
  },
  {
    "objectID": "background.html#distribution-fitting",
    "href": "background.html#distribution-fitting",
    "title": "Background",
    "section": "Distribution fitting",
    "text": "Distribution fitting\nThe previous version of HECSS used Metropolis-Hastings Markow chain Monte-Carlo (M-H MCMC) to generate the samples. This algorithm is a well-known, proven approach to sampling of the general, not-explicitly defined probability distributions. Fortunately, in our case we have a very simple, explicitly defined target distribution. Namely, the normal distribution from Equation 1 is our target.\nThis target is generated in M-H MCMC by shaping of the prior distribution using weighting of the samples. M-H algorithm achieves this goal by repeating higher probability samples while skipping lower probability ones. Effectively, this is equivalent to assigning integer weights to all samples in the prior distribution. In our case the distributions are particularly simple - being one-dimensional probability distributions. Thus we can obtain proper weighting in much more straight-forward and effective way. The details are described in Sampling optimizer section. The general idea is to calculate weights for any given prior distribution by adjusting the histogram of the prior distribution. The algorithm implemented in make_sampling goes one step further by defining non-uniform binning for the prior distribution (with one sample per bin) and calculating desired weights to match probabilities of samples to the target distribution (see Sampling optimizer for technical details). The result is a set of weights for the samples which realises the target distribution. This procedure may be applied, in principle, to any prior and target distribution (cf. Figure 3 and Figure 4). In practice, it works best if both distributions share a common support - since we cannot generate data in empty places by weighting data in other places. The procedure works even for small samples as the figures below demonstrate. Note a large difference between prior and target distribution (cf. Figure 4).\nMany programs (e.g. alamode) cannot use weighted data and require integer weights (i.e. repeated data points) on input. This form can be generated by scaling and rounding of weights to obtain any desired accuracy. The implementation in make_sampling makes such a sample with default multiplier of 4. To not exclude low-probability samples the weights may be forced to be non-zero.\n\n\nCode\n# You can try uniform distribution as your prior\n# prior = stats.uniform(0, 100)\n# Or some peaked distribution like logistic\nprior = stats.logistic(70, 50)\n\n# Generate N samples\nN = 50\nd = np.sort(prior.rvs(size=N))\n\n# Let us see our initial sample\nplt.hist(d, bins='auto', density=True);\nskip = len(d)//2000\nskip = int(max(0, skip))\nfor s in d[::skip] if skip else d:\n    plt.axvline(s, ymin=0.96, ymax=0.98, ls='-', \n                color='r', alpha=np.sqrt(1/len(d)))\nplt.ylabel('Probability density');\nplt.xlabel('Data value');\n\n\n\n\n\n\n\n\nFigure 3: Histogram of the prior distribution of the sample (red lines on top).\n\n\n\n\n\n\n\nCode\n# Helper function\nflatten = itertools.chain.from_iterable\n\n# Proof of concept - floating point waighted data\n# Target distribution, you can select any reasonable\n# function which covers the data range\ntarget = stats.logistic\nm = 40\ns = 20\ng = target(m, s)\n\n# Cumulative distribution function for data bins\ncdf = np.zeros(len(d)+1)\ncdf[1:-1] = g.cdf((d[:-1]+d[1:])/2)\n\n# boundary cdf values for the data domain\ncdf[0] = g.cdf(d[0]-(d[1]-d[0])/2)\ncdf[-1] = g.cdf(d[-1]+(d[-1]-d[-2])/2)\n\n# Data weights as change in cdf in data bin\nw = cdf[1:]-cdf[:-1]\n\n# Integer weights/data multipliers\n# We will produce Nmul times the data to simulate \n# real-valued weighting\nNmul = 4\niw = Nmul*len(d)*w\n\n# Never remove the data, block zero weights\n# This will deform (rise) the wings of the histogram\niw[np.logical_and(0.25&lt;iw, iw&lt;1)]=1\niw = np.round(iw)\n\n## This is a visualisation part\n# Bin boundaries for data weighting\n# This is for visualization only\nbb = np.zeros(len(d)+1)\nbb[1:-1] = (d[:-1]+d[1:])/2\nbb[0] = d[0]-(d[1]-d[0])/2\nbb[-1] = d[-1]+(d[-1]-d[-2])/2\n\n# bin widths\nbw = bb[1:]-bb[:-1]\n\nplt.title(f'{iw.sum():.0f} ({len(d)} unique) samples')\n\nx = np.linspace(d[0], d[-1], 300)\n\nplt.plot(x, prior.pdf(x), label='Prior distribution')\n\nplt.plot(x, g.pdf(x)/(g.cdf(bb[-1])-g.cdf(bb[0])), \n         '-', lw=1, label='Target distribution', zorder=1);\n\nplt.stairs(w/bw/w.sum(), bb, fill=False, lw=1,\n           label='Float weighted samples')\n# plt.stairs(iw/bw/iw.sum(), bb, label='integer weighted samples')\n\nNb = max(20, len(d)//10)\nplt.hist(d, weights=iw, bins=Nb, density=True, color='C1', alpha=0.4,\n         label='Integer weighted histogram')\n\n# Fit and plot target distribution to integer weighted data\nfit = target.fit(list(flatten([int(wv)*[v] for v, wv in zip(d, iw)])))\nplt.plot(x, target.pdf(x, *fit)*(target.cdf(bb[-1], *fit) - target.cdf(bb[0], *fit)),\n                                             '--', label='Fitted target distribution')\n    \nskip = len(d)//2000\nskip = int(max(0, skip))\nfor v in d[::skip] if skip else d:\n    plt.axvline(v, ymin=0.96, ymax=0.98, ls='-', \n                color='r', alpha=np.sqrt(1/len(d)))\n\nplt.ylabel('Probability density');\nplt.xlabel('Data value')\nplt.xlim(m-6*s, m+6*s)\nplt.legend(loc='upper left', bbox_to_anchor=(0.65, 0.95));\n\n\n\n\n\n\n\n\nFigure 4: Posterior distribution after application of weighting procedure. The mean and variance of the target may be selected independent of the prior sample. Try to modify m and s variables or the target distribution.",
    "crumbs": [
      "Background"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "The HECSS package is available on pypi and conda-forge additionally the package is present also in my personal anaconda channel (jochym). Installation is simple, but requires a number of other packages to be installed as well. Package managers handle these dependencies automatically.\n\n\nIt is advisable to install in a dedicated virtual environment e.g.:\npython3 -m venv venv\n. venv/bin/activate\nthen install with pip:\npip install hecss\n\n\n\nAlso installation with conda should be performed for dedicated or some other non-base environment. To create dedicated environment you can invoke conda create:\nconda create -n hecss -c conda-forge hecss\nor you can install in some working environment venv:\nconda install -n venv -c conda-forge hecss\n\n\n\nThe example data is not distributed within the library package. However, when you learn the software it is usefull to have some pre-calculated results and template configs to have a starting point. The example directory in the source distribution contains template configuration files for a calculation (VASP_3C-SiC subdirectory) and the example data calculated for the same systems (VASP_3C-SiC_calculated subdirectory). As the name suggests these are 1x1x1 and 2x2x2 supercells of the 3C-SiC (cubic silicon carbide) calculated with VASP DFT calculator.\nTo obtain the data you need to download the zip archive from the source repository: hecss-examples.zip\nThe source is published at the Gitlab hecss repository. You can access it with git (recommended, particularly if you want to contribute to the development):\ngit clone https://gitlab.com/jochym/hecss.git\nor you can download the whole distribution as a zip archive: hecss.zip The example subdirectory from the source may be downloaded directly from the source repository: hecss-examples.zip\n\n\n\nThe source is published at the Gitlab hecss repository. You can access it with git (recommended, particularly if you want to contribute to the development):\ngit clone https://gitlab.com/jochym/hecss.git\nor you can download the whole distribution as a zip archive: hecss.zip",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#install",
    "href": "setup.html#install",
    "title": "Setup",
    "section": "",
    "text": "The HECSS package is available on pypi and conda-forge additionally the package is present also in my personal anaconda channel (jochym). Installation is simple, but requires a number of other packages to be installed as well. Package managers handle these dependencies automatically.\n\n\nIt is advisable to install in a dedicated virtual environment e.g.:\npython3 -m venv venv\n. venv/bin/activate\nthen install with pip:\npip install hecss\n\n\n\nAlso installation with conda should be performed for dedicated or some other non-base environment. To create dedicated environment you can invoke conda create:\nconda create -n hecss -c conda-forge hecss\nor you can install in some working environment venv:\nconda install -n venv -c conda-forge hecss\n\n\n\nThe example data is not distributed within the library package. However, when you learn the software it is usefull to have some pre-calculated results and template configs to have a starting point. The example directory in the source distribution contains template configuration files for a calculation (VASP_3C-SiC subdirectory) and the example data calculated for the same systems (VASP_3C-SiC_calculated subdirectory). As the name suggests these are 1x1x1 and 2x2x2 supercells of the 3C-SiC (cubic silicon carbide) calculated with VASP DFT calculator.\nTo obtain the data you need to download the zip archive from the source repository: hecss-examples.zip\nThe source is published at the Gitlab hecss repository. You can access it with git (recommended, particularly if you want to contribute to the development):\ngit clone https://gitlab.com/jochym/hecss.git\nor you can download the whole distribution as a zip archive: hecss.zip The example subdirectory from the source may be downloaded directly from the source repository: hecss-examples.zip\n\n\n\nThe source is published at the Gitlab hecss repository. You can access it with git (recommended, particularly if you want to contribute to the development):\ngit clone https://gitlab.com/jochym/hecss.git\nor you can download the whole distribution as a zip archive: hecss.zip",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#calculators",
    "href": "setup.html#calculators",
    "title": "Setup",
    "section": "Calculators",
    "text": "Calculators\nTo use HECSS you need some code for calculation of energies and forces in the form of ASE calculator. At this moment two calculators are supported: ASAP/LAMMPS/OpenKIM and VASP. The first is a free, fast, effective potential calculator which can be used for testing and experimentation. It is also used in HECSS test suite. VASP is a non-free, high quality, academic DFT code which you can use for research-grade calculations. Other calculators are available in ASE (abInit, gpaw and many others). There is no reason for other ASE calculators to not work with HECSS, these two are just supported and tested for now. The next in line will be probably abInit - since this is also a high-quality, research-grade DFT code which happen to be also free.\n\nASAP/LAMMPS/OpenKIM\nThe ASAP calculator is not installed by default with HECSS package, to not force it’s installation on users which are not going to use it and to avoid blocking simple HECSS installation on systems where ASAP is not supported at the moment (e.g. Windows). To install ASAP in your conda environment run:\nconda install -c conda-forge asap3 openkim-models=2021.01.28\nNo further configuration is required for this calculator.\n\n\nVASP\nThe installation of VASP is beyond the scope of this manual. We assume that you have a working VASP setup and just installed HECSS package with its dependencies.\nTo enable use of the VASP calculator in ASE you need to configure it. This involves configuring ASE (Atomistic Simulation Environment) to be able to generate VASP input files. Refer to ASE documentation for details.\nUsually you need to: 1. Put your pseudopotential files in a dedicated directory tree as described in the docs. My setup contains a directory with three subdirs for LDA, GGA, and PBE pseudopotentials:\npotpaw  \npotpaw_GGA  \npotpaw_PBE\n\nSetting the VASP_PP_PATH environment variable to the location of this directory\nPreparing the run-calc script to execute vasp in your setup. The script must wait for the calculation to finish before it returns. The example script is included in the source and for SLURM queue manager may look similar to the following code:\n\n#!/bin/bash\n\n# This script should run vasp in current directory \n# and wait for the run to finish.\n# \n# A generic line using SLURM would look like this:\n#\n# sbatch [job_params] -W vasp_running_script\n#\n# The \"-W\" param makes the sbatch command wait for the job to finish.\n\n\nJN=`pwd`\nJN=`basename ${JN}`\n\n# Partition of the cluster\nPART=small\n\n# Number of nodes\nN=1\n\n# Number of MPI tasks\nntask=64\n\n# Name the job after directory if no label is passed as first argument\nif [ \"${1}.\" != \".\" ]; then\n  JN=${1}\nfi\n\nsbatch -W -J ${JN} -p $PART -N $N -n $ntask run-vasp-script\nYou need to adapt the script to your setup. The script works properly if you can go to the directory with the prepared VASP configuration and execute run-calc and have it run vasp in the directory and finish after the VASP job ends.",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "parallel.html",
    "href": "parallel.html",
    "title": "Parallel calculations",
    "section": "",
    "text": "Presently, these routines are implemented for VASP. It should be trivial to extend this to any calculator based on external process execution (e.g. abinit or any other which runs blocking shell script to execute the calculation). The support for internal calculators (e.g. ASAP3) should be possible, but is not trivial, and is not planned at the moment. Such in-memory calculators are probably not worth it. The real gain comes from the cluster-run calculations.",
    "crumbs": [
      "Parallel calculations"
    ]
  },
  {
    "objectID": "vasp_workflow.html",
    "href": "vasp_workflow.html",
    "title": "VASP workflow",
    "section": "",
    "text": "# Import VASP calculator and unit modules\nfrom ase.calculators.vasp import Vasp\nfrom ase import units as un\nfrom os.path import isfile\nimport os\n\n# The sample generator, monitoring display and dfset writer\nfrom hecss import HECSS\nfrom hecss.util import write_dfset\nfrom hecss.monitor import plot_stats\n\n# Numerical and plotting routines\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom collections import defaultdict\nfrom tempfile import TemporaryDirectory\nfrom glob import glob\n\n\n# Quick test using conventional unit cell\nsupercell = '1x1x1'\n\n\n# Slow more realistic test\nsupercell = '2x2x2'\n\n\n# Directory in which our project resides\nbase_dir = f'example/VASP_3C-SiC/{supercell}/'\ncalc_dir = TemporaryDirectory(dir='TMP')\n\n\n# Read the structure (previously calculated unit(super) cell)\n# The command argument is specific to the cluster setup\ncalc = Vasp(label='cryst', directory=f'{base_dir}/sc_{supercell}/', restart=True)\n\n# This just makes a copy of atoms object\n# Do not generate supercell here - your atom ordering will be wrong!\ncryst = calc.atoms.repeat(1)\n\n\n# Setup the calculator - single point energy calculation\n# The details will change here from case to case\n# We are using run-vasp from the current directory!\ncalc.set(directory=f'{calc_dir.name}/sc')\ncalc.set(command=f'{os.getcwd()}/run-calc.sh \"vasp_test\"')\ncalc.set(nsw=0)\ncryst.calc = calc\n\n\nprint('Stress tensor: ', end='')\nfor ss in calc.get_stress()/un.GPa:\n    print(f'{ss:.3f}', end=' ')\nprint('GPa')\n\nStress tensor: 0.017 0.017 0.017 0.000 0.000 0.000 GPa\n\n\n\n# Prepare space for the results.\n# We use defaultdict to automatically\n# initialize the items to empty list.\nsamples = defaultdict(lambda : [])\n\n# Space for amplitude correction data\nxsl = []\n\n\n# Build the sampler\nhecss = HECSS(cryst, calc, \n              directory=calc_dir.name,\n              w_search = True,\n              pbar=True,\n              )\n\n\nN = 5\nm, s, xscl = hecss.estimate_width_scale(5, nwork=0)\nwm = np.array(hecss._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplt.plot(wm[1], y, '.');\nx = np.linspace(0, 1.05*wm[1].max(), 2)\nfit = np.polyfit(wm[1], y, 1)\nplt.plot(x, np.polyval(fit, x), ':', label=f'{fit[1]:.4g} {fit[0]:+.4g} T')\nplt.axhline(m, ls='--', label=f'{m:.4g}±{s:.4g}')\nplt.axhspan(m-s, m+s, alpha=0.3)\nplt.ylim(m-4*s, m+4*s)\nplt.xlabel('Target temperature (K)')\nplt.ylabel('width scale ($\\\\AA/\\\\sqrt{K}$)')\nplt.legend();\n\n\n\n\n\n\n\n\n\n\n\n\n# Desired number of samples and T list.\nN = 30\nT_list = (100, 200, 300)\nfor T in T_list:\n    samples[T] += hecss.sample(T, N)\n\n\n\n\n\n\n\n\n\n\n\n# Plot the resulting distributions\nfor T in T_list:\n    plot_stats(hecss.generate(samples[T]), sqrN=True)",
    "crumbs": [
      "VASP workflow"
    ]
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "How to contribute",
    "section": "",
    "text": "Ensure the bug was not already reported by searching on GitHub under Issues.\nIf you’re unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behaviour that is not occurring.\nBe sure to add the complete error messages.\n\n\n\n\nOpen a new GitHub pull request with the patch.\nEnsure that your PR includes a test that fails without your patch, and pass with it.\nEnsure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable.\n\n\n\n\n\n\nKeep each PR focused. While it’s more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\nDo not mix style changes/fixes with “functional” changes. It’s very difficult to review such PRs and it most likely get rejected.\nDo not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\nDo not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\nIf, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and won’t need to review the whole PR again. In the exception case where you realise it’ll take many many commits to complete the requests, then it’s probably best to close the PR, do the work and then submit it again. Use common sense where you’d choose one way over another.\n\n\n\n\n\nDocs are automatically created from the notebooks in the root folder."
  },
  {
    "objectID": "CONTRIBUTING.html#did-you-find-a-bug",
    "href": "CONTRIBUTING.html#did-you-find-a-bug",
    "title": "How to contribute",
    "section": "",
    "text": "Ensure the bug was not already reported by searching on GitHub under Issues.\nIf you’re unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behaviour that is not occurring.\nBe sure to add the complete error messages.\n\n\n\n\nOpen a new GitHub pull request with the patch.\nEnsure that your PR includes a test that fails without your patch, and pass with it.\nEnsure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable."
  },
  {
    "objectID": "CONTRIBUTING.html#pr-submission-guidelines",
    "href": "CONTRIBUTING.html#pr-submission-guidelines",
    "title": "How to contribute",
    "section": "",
    "text": "Keep each PR focused. While it’s more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\nDo not mix style changes/fixes with “functional” changes. It’s very difficult to review such PRs and it most likely get rejected.\nDo not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\nDo not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\nIf, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and won’t need to review the whole PR again. In the exception case where you realise it’ll take many many commits to complete the requests, then it’s probably best to close the PR, do the work and then submit it again. Use common sense where you’d choose one way over another."
  },
  {
    "objectID": "CONTRIBUTING.html#do-you-want-to-contribute-to-the-documentation",
    "href": "CONTRIBUTING.html#do-you-want-to-contribute-to-the-documentation",
    "title": "How to contribute",
    "section": "",
    "text": "Docs are automatically created from the notebooks in the root folder."
  },
  {
    "objectID": "cli.html",
    "href": "cli.html",
    "title": "CLI",
    "section": "",
    "text": "The HECSS sampler can be also used from the command line using hecss-sampler command:\n\n\n$ hecss-sampler -V\n\nHECSS, version 0.5.26\nHigh Efficiency Configuration Space Sampler\n(C) 2021-2024 by Paweł T. Jochym\n    License: GPL v3 or later\n\n$ hecss-sampler --help\n\nUsage: hecss-sampler [OPTIONS] FNAME\n\n  Run HECSS sampler on the structure in the provided file (FNAME) Read the\n  docs at: https://jochym.github.io/hecss/\n\n  FNAME - Supercell structure file. The containing \n          directory must be readable by Vasp(restart).\n          Usually this is a CONTCAR file for a supercell.\n\nOptions:\n  -W, --workdir PATH      Work directory\n  -l, --label TEXT        Label for the calculations.\n  -T, --temp FLOAT        Target temperature in Kelvin.\n  -w, --width FLOAT       Initial scale of the prior distribution\n  -a, --ampl PATH         Initialise amplitude correction from the file.\n  -s, --scale PATH        Save amplitude correction history\n  -m, --symprec FLOAT     Symmetry search tolerance.\n  -C, --calc TEXT         ASE calculator to be used for the job. Supported\n                          calculators: VASP (default)\n  -S, --setups TEXT       setups parameter of the calculator to force use of the\n                          particular variants of pseudopotentials in the\n                          calculations. By default pseudopotentials are guessed\n                          from the POTCAR in the supercell directory.\n  -n, --nodfset           Do not write DFSET file for ALAMODE\n  -d, --dfset TEXT        Name of the DFSET file\n  -N, --nsamples INTEGER  Number of samples to be generated\n  -e, --neta INTEGER      Number of samples for width scale estimation\n  -c, --command TEXT      Command to run calculator\n  -k, --nwork INTEGER     Number of parallel workers to run (0=unlimited)\n  -p, --pbar              Do not show progress bar\n  -V, --version           Show the version and exit.\n  -h, --help              Show this message and exit.\n\n\n\nTo use it you need to prepare:\n\nrun-calc script which should start the VASP calculation. You need to put this script in the root of your project tree. The example of such a script is included in the source as run-calc.example. :\n\n#!/bin/bash\n\n# This script should run vasp in current directory \n# and wait for the run to finish.\n# \n# A generic line using SLURM would look like this:\n#\n# sbatch [job_params] -W vasp_running_script\n#\n# The \"-W\" param makes the sbatch command wait for the job to finish.\n\n\nJN=`pwd`\nJN=`basename ${JN}`\n\n# Partition of the cluster\nPART=small\n\n# Number of nodes\nN=1\n\n# Number of MPI tasks\nntask=64\n\n# Name the job after directory if no label is passed as first argument\nif [ \"${1}.\" != \".\" ]; then\n  JN=${1}\nfi\n\nsbatch -W -J ${JN} -p $PART -N $N -n $ntask run-vasp-script\n\nA directory with fully converged and optimized supercell structure which can be read in by the ASE Vasp(restart=...) command\nA directory for the generated samples.\n\nThe directory tree may look like this:\nmy_project ----- sc\n             |\n             +-- T_100\n             |\n             +-- T_200\n             |\n             +-- ...\n             |\n             +-- run-calc\nYou execute the sampler from the my_project directory (remember to activate your virtual environment first). Generation of N=30 samples at T=100K:\n~$ cd my_project\n~$ hecss_sampler -W T_100 -T 100 -N 30 -c ./run-calc sc/CONTCAR\nThe above command will put the generated samples inside the T_100 directory, together with the DFSET file with displacement-force data extracted from the calculation. The calculation may take a long time. Thus it is advisable to execute the hecss command inside screen (or some similar terminal multiplexer) to prevent the break of the calculation in case of session disconnection. The hecss command shows a progress to guide you through the calculation (ETA, time/it, data about last sample etc.). The example run is included at the bottom of this document.",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "cli.html#command-line-hecss-sampler",
    "href": "cli.html#command-line-hecss-sampler",
    "title": "CLI",
    "section": "",
    "text": "The HECSS sampler can be also used from the command line using hecss-sampler command:\n\n\n$ hecss-sampler -V\n\nHECSS, version 0.5.26\nHigh Efficiency Configuration Space Sampler\n(C) 2021-2024 by Paweł T. Jochym\n    License: GPL v3 or later\n\n$ hecss-sampler --help\n\nUsage: hecss-sampler [OPTIONS] FNAME\n\n  Run HECSS sampler on the structure in the provided file (FNAME) Read the\n  docs at: https://jochym.github.io/hecss/\n\n  FNAME - Supercell structure file. The containing \n          directory must be readable by Vasp(restart).\n          Usually this is a CONTCAR file for a supercell.\n\nOptions:\n  -W, --workdir PATH      Work directory\n  -l, --label TEXT        Label for the calculations.\n  -T, --temp FLOAT        Target temperature in Kelvin.\n  -w, --width FLOAT       Initial scale of the prior distribution\n  -a, --ampl PATH         Initialise amplitude correction from the file.\n  -s, --scale PATH        Save amplitude correction history\n  -m, --symprec FLOAT     Symmetry search tolerance.\n  -C, --calc TEXT         ASE calculator to be used for the job. Supported\n                          calculators: VASP (default)\n  -S, --setups TEXT       setups parameter of the calculator to force use of the\n                          particular variants of pseudopotentials in the\n                          calculations. By default pseudopotentials are guessed\n                          from the POTCAR in the supercell directory.\n  -n, --nodfset           Do not write DFSET file for ALAMODE\n  -d, --dfset TEXT        Name of the DFSET file\n  -N, --nsamples INTEGER  Number of samples to be generated\n  -e, --neta INTEGER      Number of samples for width scale estimation\n  -c, --command TEXT      Command to run calculator\n  -k, --nwork INTEGER     Number of parallel workers to run (0=unlimited)\n  -p, --pbar              Do not show progress bar\n  -V, --version           Show the version and exit.\n  -h, --help              Show this message and exit.\n\n\n\nTo use it you need to prepare:\n\nrun-calc script which should start the VASP calculation. You need to put this script in the root of your project tree. The example of such a script is included in the source as run-calc.example. :\n\n#!/bin/bash\n\n# This script should run vasp in current directory \n# and wait for the run to finish.\n# \n# A generic line using SLURM would look like this:\n#\n# sbatch [job_params] -W vasp_running_script\n#\n# The \"-W\" param makes the sbatch command wait for the job to finish.\n\n\nJN=`pwd`\nJN=`basename ${JN}`\n\n# Partition of the cluster\nPART=small\n\n# Number of nodes\nN=1\n\n# Number of MPI tasks\nntask=64\n\n# Name the job after directory if no label is passed as first argument\nif [ \"${1}.\" != \".\" ]; then\n  JN=${1}\nfi\n\nsbatch -W -J ${JN} -p $PART -N $N -n $ntask run-vasp-script\n\nA directory with fully converged and optimized supercell structure which can be read in by the ASE Vasp(restart=...) command\nA directory for the generated samples.\n\nThe directory tree may look like this:\nmy_project ----- sc\n             |\n             +-- T_100\n             |\n             +-- T_200\n             |\n             +-- ...\n             |\n             +-- run-calc\nYou execute the sampler from the my_project directory (remember to activate your virtual environment first). Generation of N=30 samples at T=100K:\n~$ cd my_project\n~$ hecss_sampler -W T_100 -T 100 -N 30 -c ./run-calc sc/CONTCAR\nThe above command will put the generated samples inside the T_100 directory, together with the DFSET file with displacement-force data extracted from the calculation. The calculation may take a long time. Thus it is advisable to execute the hecss command inside screen (or some similar terminal multiplexer) to prevent the break of the calculation in case of session disconnection. The hecss command shows a progress to guide you through the calculation (ETA, time/it, data about last sample etc.). The example run is included at the bottom of this document.",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "cli.html#width-scale-estimation",
    "href": "cli.html#width-scale-estimation",
    "title": "CLI",
    "section": "Width scale estimation",
    "text": "Width scale estimation\nCalling the sampler with N=0 runs only width scale (eta) estimation procedure for the temperature range 0-T Kelvin. The calculated value may be used as the -w parameter in subsequent calculations. Possibly even for temperatures outside of this range.\n\n\n\n\n\n$ hecss-sampler -W TMP/tmp300lbafg -T 1000 -N 0 -e 10 -c ./run-calc.sh -k 0  example/VASP_3C-SiC/1x1x1/sc_1x1x1/CONTCAR\n\nHECSS (0.5.26)\nSupercell:      example/VASP_3C-SiC/1x1x1/sc_1x1x1/CONTCAR\nTemperature:    1000.0K\nWork directory: TMP/tmp300lbafg\nCalculator:     VASP\nSetups guessed from example/VASP_3C-SiC/1x1x1/sc_1x1x1/POTCAR: {'C': '', 'Si': ''}\nEstimating width scale.\nWidth scale from 10 pts.: 1.83+/-0.27\nWidth scale estimation run (N&lt;2). Not running sampling.",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "cli.html#calculating-amplitude-correction-data",
    "href": "cli.html#calculating-amplitude-correction-data",
    "title": "CLI",
    "section": "Calculating amplitude correction data",
    "text": "Calculating amplitude correction data\nThe amplitude correction data can be saved into the file (-s parameter) and used in subsequent calculations (see below). This will speed up the initial equilibration of the degrees of freedom. This will be merged with eta estimation in future versions.\n\n\n\n\n\n$ hecss-sampler -W TMP/tmp300lbafg -T 300 -N 10 -w 1.85 -c ./run-calc.sh -s scale.dat example/VASP_3C-SiC/1x1x1/sc_1x1x1/CONTCAR\n\nHECSS (0.5.26)\nSupercell:      example/VASP_3C-SiC/1x1x1/sc_1x1x1/CONTCAR\nTemperature:    300.0K\nWork directory: TMP/tmp300lbafg\nCalculator:     VASP\nSetups guessed from example/VASP_3C-SiC/1x1x1/sc_1x1x1/POTCAR: {'C': '', 'Si': ''}\nSampling configurations\nGenerating distribution centered at: 291.342 K\nAverage width scale (9 pnts): 1.8+/-0.00404",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "cli.html#calculate-initial-amplitude-correction",
    "href": "cli.html#calculate-initial-amplitude-correction",
    "title": "CLI",
    "section": "Calculate initial amplitude correction",
    "text": "Calculate initial amplitude correction\nBy saving the amplitude correction coefficients into the file with -s option of the sampler we can initialise following calculations with proper relations of relative displacement amplitudes. This may be also used to continue the calculations with minimal startup overhead.\n\n\n$ calculate-xscale --help\n\nUsage: calculate-xscale [OPTIONS] SUPERCELL SCALE\n\n  Calculate initial values for amplitude correction coefficients  from the scale\n  file data for the specified supercell.\n\nOptions:\n  -o, --output PATH   Write output to the file.\n  -s, --skip INTEGER  Skip this number of samples at the beginning\n  -V, --version       Show the version and exit.\n  -h, --help          Show this message and exit.\n\n$ calculate-xscale -o TMP/tmp300lbafg/iscale.dat -s 10 example/VASP_3C-SiC/1x1x1/sc_1x1x1/CONTCAR TMP/tmp300lbafg/T_300.0K/scale.dat\n\nDone. The initial scale saved to: TMP/tmp300lbafg/iscale.dat",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "cli.html#continue-the-calculation",
    "href": "cli.html#continue-the-calculation",
    "title": "CLI",
    "section": "Continue the calculation",
    "text": "Continue the calculation\n\n\n\n\n\n$ hecss-sampler -W TMP/tmp_jaucdpz -T 300 -N 10 -w 1.85 -c ./run-calc.sh -s scale.dat -a TMP/tmp300lbafg/iscale.dat example/VASP_3C-SiC/1x1x1/sc_1x1x1/CONTCAR\n\nHECSS (0.5.26)\nSupercell:      example/VASP_3C-SiC/1x1x1/sc_1x1x1/CONTCAR\nTemperature:    300.0K\nWork directory: TMP/tmp_jaucdpz\nCalculator:     VASP\nSetups guessed from example/VASP_3C-SiC/1x1x1/sc_1x1x1/POTCAR: {'C': '', 'Si': ''}\nSampling configurations\nGenerating distribution centered at: 322.607 K\nAverage width scale (9 pnts): 1.87+/-0.00431",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "cli.html#sampling-re-shaping",
    "href": "cli.html#sampling-re-shaping",
    "title": "CLI",
    "section": "Sampling re-shaping",
    "text": "Sampling re-shaping\nThe reshaper of the sample set to any given temperature.\n\n\n$ reshape-sample --help\n\nUsage: reshape-sample [OPTIONS] DFSET [T]\n\n  Reshape the sample to the normal distribution centered around mean energy\n  (temperature), or around provided temperature T (Kelvin). The reshaping is\n  done by adjusting weighting of the samples by repeating the ones which should\n  be up-weighted.  The parameters are the variants of the weighting algorithm\n  (see the docs)\n\n  The procedure reads and produces a file with in the DFSET format. For the\n  'check' function to work the parameter must point to the root directory  of\n  the calculated samples. The checked directories will be in the form:\n  '{root}/nnnn'.\n\n  In check mode the raw file is *not* reshaped, just filtered.\n\nOptions:\n  -N, --nmul INTEGER  Sample length multiplier (default: 4)\n  -p, --prob FLOAT    Probability treshold (default: 0.25)\n  -w                  Force non-zero weights for samples above probability\n                      treshold. (default: True)\n  -b                  Border samples account for the rest of domain\n  -c, --check PATH    Check and skip unconverged samples in calc directory.\n  -o, --output PATH   Write output to the file.\n  -d                  Plot debug plots\n  -V, --version       Show the version and exit.\n  --help              Show this message and exit.\n\n$ reshape-sample  -d -o TMP/DFSET.dat TMP/DFSET_raw.dat\n\n\n\n\n\n\n\n\n\n\nDone. Distribution reshaped to 306.97 K.\nDone. Saving to: TMP/DFSET.dat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$ reshape-sample  -N 1 -w -d -o TMP/tmp300lbafg/T_300.0K/DFSET.dat --check TMP/tmp300lbafg/T_300.0K/smpl TMP/tmp300lbafg/T_300.0K/DFSET.dat.raw\n\nChecking convergence in TMP/tmp300lbafg/T_300.0K/smpl/nnnn\nNumber of converged calculations: 10/10\nRewriting the raw dfset (skipping reshape).\nDone. Saving to: TMP/tmp300lbafg/T_300.0K/DFSET.dat",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "cli.html#command-line-statistics-monitoring",
    "href": "cli.html#command-line-statistics-monitoring",
    "title": "CLI",
    "section": "Command line statistics monitoring",
    "text": "Command line statistics monitoring\nThis simple command line interface to the statistics plotting function allows for quick monitoring of the running calculation. If the sixelplot package is installed it is even possible to plot hi-res plots in the remote terminal supporting sixel standard (e.g. mlterm, xterm on Linux, iterm2 on OSX).\n\n\n$ plot-stats --help\n\nUsage: plot-stats [OPTIONS] DFSET [T]\n\n  Plot the statistics of the samples from the DFSET file. Use T(K) as a\n  reference target temperature. Optionally  write out the plot to the output\n  graphics file.\n\nOptions:\n  -n, --sqrn          Show sqrt(N) bars on the histogram.\n  -s, --sixel         Use SixEl driver for terminal graphics.\n  -w, --width FLOAT   Width of the figure.\n  -h, --height FLOAT  Height of the figure.\n  -o, --output PATH   Write output to the file.\n  -x                  Make plot in an interactive window\n  -V, --version       Show the version and exit.\n  --help              Show this message and exit.\n\n$ plot-stats -n -w 7 -h 4 TMP/DFSET_raw.dat 300\n\n\n\n\n\n\n\n\n\n\n\n\n\n$ plot-stats -n -w 7 -h 4 TMP/DFSET.dat \n\n\n\n\n\n\n\n\n\n\n\n\n\n$ plot-stats -n -w 7 -h 4 example/VASP_3C-SiC_calculated/2x2x2/T_1200K/DFSET.dat 1200",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "cli.html#command-line-phonon-monitoring",
    "href": "cli.html#command-line-phonon-monitoring",
    "title": "CLI",
    "section": "Command line phonon monitoring",
    "text": "Command line phonon monitoring\nThis simple command line interface to the phonon plotting function allows for quick monitoring of the phonon calculation. If the sixelplot package is installed it is even possible to plot hi-res plots in the remote terminal supporting sixel standard (e.g. mlterm, xterm on Linux, iterm2 on OSX).\n\n\n$ plot-bands --help\n\nUsage: plot-bands [OPTIONS] [BANDS]...\n\n  Plot the phonon dispersion from the file generated by ALAMODE. Optionally\n  write out the plot to the output graphics file.\n\nOptions:\n  -s, --sixel         Use SixEl driver for terminal graphics.\n  -n, --nodecor       Decorate the plot.\n  -w, --width FLOAT   Width of the figure.\n  -h, --height FLOAT  Height of the figure.\n  -o, --output PATH   Write output to the file.\n  -l, --label TEXT    Label(s) for the plot. Comma-separated list\n  -x                  Make plot in an interactive window\n  -V, --version       Show the version and exit.\n  --help              Show this message and exit.\n\n$ plot-bands -w 7 -h 4 -l '300K,600K,3000K' example/VASP_3C-SiC_calculated/2x2x2/T_300K/phon/cryst.bands example/VASP_3C-SiC_calculated/2x2x2/T_600K/phon/cryst.bands example/VASP_3C-SiC_calculated/2x2x2/T_3000K/phon/cryst.bands",
    "crumbs": [
      "CLI"
    ]
  },
  {
    "objectID": "parwidth.html",
    "href": "parwidth.html",
    "title": "Parallel width estimator",
    "section": "",
    "text": "# Quick test using conventional unit cell\nsupercell = '1x1x1'\n# Slow more realistic test\nsupercell = '2x2x2'\n# Directory in which our project resides\nbase_dir = f'example/VASP_3C-SiC_calculated/{supercell}/'\ncalc_dir = TemporaryDirectory(dir='TMP')\n# Read the structure (previously calculated unit(super) cell)\n# The command argument is specific to the cluster setup\ncalc = Vasp(label='cryst', directory=f'{base_dir}/sc/', restart=True)\n\n# This just makes a copy of atoms object\n# Do not generate supercell here - your atom ordering will be wrong!\ncryst = calc.atoms.repeat(1)\nprint('Stress tensor: ', end='')\nfor ss in calc.get_stress()/un.GPa:\n    print(f'{ss:.3f}', end=' ')\nprint('GPa')\nEp0 = calc.get_potential_energy()\n\nStress tensor: 0.017 0.017 0.017 0.000 0.000 0.000 GPa\n# Setup the calculator - single point energy calculation\n# The details will change here from case to case\n# We are using run-vasp from the current directory!\ncalc.set(directory=f'{calc_dir.name}/sc')\ncalc.set(command=f'{os.getcwd()}/run-calc.sh \"async\"')\ncalc.set(nsw=0)\ncryst.calc = calc\n# Prepare space for the results.\n# We use defaultdict to automatically\n# initialize the items to empty list.\nsamples = defaultdict(lambda : [])\n\n# Space for amplitude correction data\nxsl = []\n# Build the sampler\nhecss = HECSS(cryst, calc, \n              directory=calc_dir.name,\n              w_search = True,\n              pbar=True,\n              )\nhecss.Ep0 = Ep0",
    "crumbs": [
      "Parallel width estimator"
    ]
  },
  {
    "objectID": "parwidth.html#triggering-parallel-calculations",
    "href": "parwidth.html#triggering-parallel-calculations",
    "title": "Parallel width estimator",
    "section": "Triggering parallel calculations",
    "text": "Triggering parallel calculations\nThe parallel version of the estimate_width_scale method is triggered by setting nwork parameter to number of parallel workers which should be used. If nwork=0 the number of workers will be equal to number of required samples N.\n\nN = 10\nm, s, xscl = hecss.estimate_width_scale(1, Tmax=2000)\n\n\n\n\n\nawait hecss.__estimate_width_scale_aio(N//2, Tmax=2000, nwork=N//2)\n\n\nm, s, xscl = hecss.estimate_width_scale(N, Tmax=2000, nwork=N//2)\n\n\n\n\n\nm, s, xscl = hecss.estimate_width_scale(N//2, Tmax=2000, nwork=3)\n\n\n\n\n\nm, s, xscl = hecss.estimate_width_scale(2*N, Tmax=2000, nwork=N)\n\n\n\n\n\nm, s, xscl = hecss.estimate_width_scale(3*N, Tmax=2000, nwork=0)\n\n\n\n\n\n# plt.semilogy()\nwm = np.array(hecss._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplt.plot(wm[1], y, '.');\nx = np.linspace(0, 1.05*wm[1].max(), 2)\nfit = np.polyfit(wm[1], y, 1)\nplt.plot(x, np.polyval(fit, x), ':', label=f'{fit[1]:.4g} {fit[0]:+.4g} T')\nplt.axhline(m, ls='--', label=f'{m:.4g}±{s:.4g}')\nplt.axhspan(m-s, m+s, alpha=0.3)\nplt.ylim(m-4*s, m+4*s)\n# plt.ylim(0, m+4*s)\nplt.xlabel('Target temperature (K)')\nplt.ylabel('width scale ($\\\\AA/\\\\sqrt{K}$)')\nplt.grid()\nplt.legend();\n\n\n\n\n\n\n\n\n\nwm = np.array(hecss._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplt.plot(y, '.')\nrm = np.array([y[:l].mean() for l in range(1, len(y))])\nrv = np.array([y[:l].std() for l in range(1, len(y))])\nplt.plot(rm, '-', label='$ (x_0 + ... + x_{n-1})/n$')\nplt.plot(rm + rv, ':', lw=1, color='C1')\nplt.plot(rm - rv, ':', lw=1, color='C1')\nplt.axhline(m, ls='--', label=f'{m:.4g}±{s:.4g}')\nplt.axhspan(m-s, m+s, alpha=0.3)\nplt.xlabel('Sample number ($n$)')\nplt.ylabel('width scale ($\\\\AA/\\\\sqrt{K}$)')\nplt.grid()\nplt.legend();",
    "crumbs": [
      "Parallel width estimator"
    ]
  },
  {
    "objectID": "parwidth.html#directory-clean-up-routine",
    "href": "parwidth.html#directory-clean-up-routine",
    "title": "Parallel width estimator",
    "section": "Directory clean-up routine",
    "text": "Directory clean-up routine\n\nThis is executed by default to clean-up after the tests. If you want to clean up the directory after running the notebook change CLEANUP to True. The directory is always cleaned after successful tests run in command line mode. The default False value skips the cleanup for manual runs to leave calculation directory for inspection.",
    "crumbs": [
      "Parallel width estimator"
    ]
  },
  {
    "objectID": "optimize.html",
    "href": "optimize.html",
    "title": "Distribution reshape",
    "section": "",
    "text": "This code is an implementation of the idea to replace crude weighting produced by the Metropolis-Hastings algorithm by weights derived directly from the PDF of the target distribution. This makes the acceptance ratio essentially 100% and allows for tricks like changing of the target distribution (e.g. shifting of the target temperature of the sample or even scanning of the temperature range using prior distribution generated using plan_T_scan).\nThe implementation here, derives the weights directly from the PDF of the target distribution by assigning non-uniform bins to each data point and calculating change in CDF across each bin. The resulting data uses weighting in similar way as the M-H sampling does, but exploits the knowledge of the sample distribution and target PDF to make it more effective.\nsource",
    "crumbs": [
      "Distribution reshape"
    ]
  },
  {
    "objectID": "optimize.html#target-temperature-control",
    "href": "optimize.html#target-temperature-control",
    "title": "Distribution reshape",
    "section": "Target temperature control",
    "text": "Target temperature control\nIf the amplitude of displacement is not tightly controlled by the width searching algorithm (w_search parameter in the HECSS constructor), the mean energy of the sample will be shifted from the target value. The distribution reshaping algorithm in make_sampling may shift the result closer to the target but cannot create data out of thin air. This is illustrated in the example below. In first case (Section 1.1) we have forced the algorithm to create distribution at initial target temperature (T), which produces very distorted sample.\nIn the second case (Section 1.2) the target temperature is selected well within the data domain (Tmu which is actually the mean of the sample) which generates a well-balanced and uniform sampling of the target distribution, although at a slightly shifted temperature.\n\nShifted target\n\nwd = make_sampling(smpls, T, probTH=0.25, Nmul=4, \n                   nonzero_w=True, border=False, debug=True)\nplt.show()\nplot_stats(wd, T, sqrN=True, show=False)\n# plt.savefig('AUX/hecss_post.pdf', bbox_inches='tight')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTarget at the mean\n\nwd = make_sampling(smpls, Tmu, probTH=0.25, Nmul=4, \n                   nonzero_w=True, border=False, debug=True)\nplt.show()\nplot_stats(wd, Tmu, sqrN=True, show=False)\n# plt.savefig('AUX/hecss_post.pdf', bbox_inches='tight')",
    "crumbs": [
      "Distribution reshape"
    ]
  },
  {
    "objectID": "optimize.html#manual-temperature-scan",
    "href": "optimize.html#manual-temperature-scan",
    "title": "Distribution reshape",
    "section": "Manual temperature scan",
    "text": "Manual temperature scan\nThe ability to re-shape the sample makes it possible to scan the whole range of temperatures by adding samples from several temperatures and subsequently drawing from the whole set samples representing any target temperature in the covered range. The sampled temperatures may be selected manually or using automatic procedure from plan_T_scan. Here we just select few temperatures and run the procedure to test the weighting procedure on the non-gaussian prior.\n\nuni = {TT:hecss.sample(TT, N) for TT in (260, 300, 340)}\n\n\n\n\n\n\n\n\n\n\n\ne_dist = {t:np.array([s[-1] for s in d]) for t, d in uni.items()}\ne_uni = np.concatenate(tuple(e_dist.values()))\nusmp = []\nfor s in uni.values():\n    usmp += s\n\nfor TT, ed in e_dist.items():\n    plt.hist(ed, bins=40, label=f'T={TT}K', alpha=0.25, range=(e_uni.min(), e_uni.max()))\nplt.hist(e_uni, bins=40, histtype='step', stacked=True, range=(e_uni.min(), e_uni.max()))\nplt.legend();\n\n\n\n\n\n\n\n\n\nwd = make_sampling(usmp, T=280, N=4*N, nonzero_w=True, debug=True)\nprint(len(usmp), len(wd))\nplt.legend(loc='upper right', bbox_to_anchor=(1.0, 0.95))\nplt.show();\nplot_stats(wd, sqrN=True, show=False)\nplt.savefig(f'AUX/T_fit_{T=:.0f}K.pdf', bbox_inches='tight')\n\n\n\n\n\n\n\n\n1500 2026",
    "crumbs": [
      "Distribution reshape"
    ]
  },
  {
    "objectID": "xscale.html",
    "href": "xscale.html",
    "title": "Amplitude correction extraction",
    "section": "",
    "text": "source\n\n\n\n plot_virial_stat (cryst, smpl, normal=True)\n\n\nfrom hecss.monitor import plot_stats, plot_xs_stat\nfrom hecss.monitor import plot_acceptance_history, plot_dofmu_stat\nfrom hecss.util import select_asap_model, create_asap_calculator\nfrom hecss.util import calc_init_xscale\nfrom tqdm.auto import tqdm\n\n\nmodel = select_asap_model('Universal')\nprint(f'Using potential model: {model}')\n\noliv = ase.io.read('data/spinel.POSCAR')\noliv.calc = create_asap_calculator(model)\nprint(f'Space group: {spglib.get_spacegroup(get_cell_data(oliv))}')\n\nUsing potential model: LJ_ElliottAkerson_2015_Universal__MO_959249795837_003\nSpace group: Fd-3m (227)\n\n\n\nN = 100\n\nsampler = HECSS(oliv, lambda : create_asap_calculator(model))\nm, s, xscl = sampler.estimate_width_scale(N, Tmax=1000)\n\n\nwm = np.array(sampler._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplot_hist(y, '', 0, normal=False, df=3*len(oliv))\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.semilogx()\nplot_virial_stat(oliv, sampler._eta_samples, normal=False);\n\n\n\n\n\n\n\n\n\nT = 600\nN = 1_000\ndofmu = []\nxsl = []\nsampler.xscale_init = xscl.copy()\nosamples = sampler.sample(T, N, dofmu_list=dofmu, xscale_list=xsl)\n# osamples = [s for s in tqdm(sampler._sampler(T, N, \n#                                             dofmu_list=dofmu, xscale_list=xsl), total=N)]\n\n\nplot_virial_stat(oliv, osamples, normal=False);\n\n\n\n\n\n\n\n\n\nplot_dofmu_stat(oliv, dofmu, skip=0, window=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_xs_stat(oliv, xsl, skip=0, window=10)",
    "crumbs": [
      "Amplitude correction extraction"
    ]
  },
  {
    "objectID": "xscale.html#lamps-data-on-olivine",
    "href": "xscale.html#lamps-data-on-olivine",
    "title": "Amplitude correction extraction",
    "section": "",
    "text": "source\n\n\n\n plot_virial_stat (cryst, smpl, normal=True)\n\n\nfrom hecss.monitor import plot_stats, plot_xs_stat\nfrom hecss.monitor import plot_acceptance_history, plot_dofmu_stat\nfrom hecss.util import select_asap_model, create_asap_calculator\nfrom hecss.util import calc_init_xscale\nfrom tqdm.auto import tqdm\n\n\nmodel = select_asap_model('Universal')\nprint(f'Using potential model: {model}')\n\noliv = ase.io.read('data/spinel.POSCAR')\noliv.calc = create_asap_calculator(model)\nprint(f'Space group: {spglib.get_spacegroup(get_cell_data(oliv))}')\n\nUsing potential model: LJ_ElliottAkerson_2015_Universal__MO_959249795837_003\nSpace group: Fd-3m (227)\n\n\n\nN = 100\n\nsampler = HECSS(oliv, lambda : create_asap_calculator(model))\nm, s, xscl = sampler.estimate_width_scale(N, Tmax=1000)\n\n\nwm = np.array(sampler._eta_list).T\ny = np.sqrt((3*wm[1]*un.kB)/(2*wm[2]))\nplot_hist(y, '', 0, normal=False, df=3*len(oliv))\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.semilogx()\nplot_virial_stat(oliv, sampler._eta_samples, normal=False);\n\n\n\n\n\n\n\n\n\nT = 600\nN = 1_000\ndofmu = []\nxsl = []\nsampler.xscale_init = xscl.copy()\nosamples = sampler.sample(T, N, dofmu_list=dofmu, xscale_list=xsl)\n# osamples = [s for s in tqdm(sampler._sampler(T, N, \n#                                             dofmu_list=dofmu, xscale_list=xsl), total=N)]\n\n\nplot_virial_stat(oliv, osamples, normal=False);\n\n\n\n\n\n\n\n\n\nplot_dofmu_stat(oliv, dofmu, skip=0, window=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_xs_stat(oliv, xsl, skip=0, window=10)",
    "crumbs": [
      "Amplitude correction extraction"
    ]
  },
  {
    "objectID": "xscale.html#vasp-calculations",
    "href": "xscale.html#vasp-calculations",
    "title": "Amplitude correction extraction",
    "section": "VASP calculations",
    "text": "VASP calculations\n\nHere we use pre-calculated vasp data for 3C-SiC 2x2x2 suprecell\n\n\n# Use more realistic pre-calculated data \nsupercell = '2x2x2'\n\n\nsc = ase.io.read(f'example/VASP_3C-SiC/{supercell}/sc_{supercell}/vasprun.xml')\n\n\ne0 = sc.get_potential_energy()\n\n\neqdelta=0.05\neqsigma=0.2\n\nnat = len(sc)\ndim = (nat, 3)\nsymprec=1e-5\nsymm = get_symmetry_dataset(get_cell_data(sc), symprec=symprec)\ndofmap = symm['mapping_to_primitive']\ndof = list(sorted(set(dofmap)))\ndofmu = np.ones((len(dof), 3))\nmu = np.ones(dim)\n\n/home/jochym/.conda/envs/dev/lib/python3.11/site-packages/spglib/spglib.py:115: DeprecationWarning: dict interface (SpglibDataset['mapping_to_primitive']) is deprecated.Use attribute interface ({self.__class__.__name__}.{key}) instead\n  warnings.warn(\n\n\n\nxscale = np.ones(dim)\ndofxs = np.array([xscale[dofmap==d,:].mean(axis=0) for d in dof])\nvt = []\n\n# for i, sfn in enumerate(sorted(glob(f'TMP/calc_{supercell}/w_est/*/vasprun.xml'))):\nfor i, sfn in enumerate(sorted(glob(f'example/VASP_3C-SiC_calculated/calc_{supercell}/w_est/*/vasprun.xml'))):\n    s = ase.io.read(sfn)\n    dx = normalize_conf(s, sc)[0] - sc.get_positions()\n    try :\n        f = s.get_forces()\n        e = (s.get_potential_energy() - e0)/nat\n        v = np.abs(dx*f)\n        v = dx*f\n        v /= v.mean()\n        dofv = np.array([v[dofmap==d,:].mean(axis=0) for d in dof])\n        # dofxs *= (1-2*eqdelta*(expit((np.sqrt(dofmu)-1)/eqsigma)-0.5))\n        # dofxs /= np.sqrt((dofxs**2).mean())\n        vt.append(dofv.reshape(-1))\n    except RuntimeError:\n        continue\n\nvt = np.array(vt).reshape(-1,2,3)\nvta = vt.reshape(-1,2,3).mean(axis=-1)\nmu = vta.cumsum(axis=0)\nmu /= np.arange(1,len(mu)+1)[:, None]\n\n\n# plt.semilogy()\nplt.plot(mu, '-')\nplt.plot(vta, '.', ms=1)\nfor dofn in 0, 1:\n    m = vta[:,dofn].mean()\n    s = vta[:,dofn].std()\n    plt.axhline(m, ls=':', color=f'C{dofn}')\n    plt.axhspan(m-s, m+s, color=f'C{dofn}', alpha=0.2)\nmu[-1]\n\narray([1.01036281, 0.98963719])\n\n\n\n\n\n\n\n\n\n\nx=np.linspace(0.5,1.5,100)\nfor dofn in 0, 1:\n    rv = vt[:,dofn,:].mean(axis=-1).reshape(-1)\n    plt.hist(rv, density=True, bins='auto',\n             color=f'C{dofn}', alpha=0.33, label=f'{dofn}')\n    fit = chi.fit(rv, f0=12)\n    plt.plot(x, chi.pdf(x, *fit), ls=':', color=f'C{dofn}')\n    fit = norm.fit(rv)\n    plt.plot(x, norm.pdf(x, *fit), ls='-', color=f'C{dofn}')",
    "crumbs": [
      "Amplitude correction extraction"
    ]
  },
  {
    "objectID": "util.html",
    "href": "util.html",
    "title": "Utility functions",
    "section": "",
    "text": "source\n\nnormalize_conf\n\n normalize_conf (c, base)\n\n*Normalize the configuration c relative to the basic structure base. Normalization is performed by “nuwrapping” the displacements of atoms when they cross the periodic boundary conditions in such a way that the atoms are not “jumping” from one side of the cell to the other.\nE.g. if the atom at r=(0,0,0) goes to the relative position (-0.01, 0, 0) it is “wrapped” by PBC to the r=(0.99, 0, 0). Thus if we naiively calculate the displacement we will get a large positive displacement (0.99 of the cell vector) instead of a small negative one.\nThis function reverses that process making the positions suitable for differentiation. The positions may be part of a continous trajectory or just independent configurations. This makes it impossible for described procedure to work if the displacements are above 1/2 of the unit cell. For sefety this implementation is limited to displacements &lt; 1/3 of the unit cell. If any coordinate changes by more then 1/3 the function will rise an AssertionError exception.\nThis implementation is not suitable for tracking positions in the system with systematic drift (e.g. long MD trajectory with non-perfect momentum conservation). For stronger implementation suitable for such cases look at dxutils package.*\n\nsource\n\n\nload_dfset\n\n load_dfset (fn)\n\nLoad contents of the DFSET flie and return dfset array\n\nsource\n\n\nget_dfset_len\n\n get_dfset_len (fn)\n\n\nsource\n\n\nwrite_dfset\n\n write_dfset (fn, c, comment='')\n\nAppend displacement-force data from the conf to the fn file. The format is suitable for use as ALAMODE DFSET file. Optionaly you can provide configuration number in n. File need not exist prior to first call. If it does not it will be created.\n/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: Unknown section Input\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: Unknown section Output\n  else: warn(msg)\n\nsource\n\n\ncalc_init_xscale\n\n calc_init_xscale (cryst, xsl, skip=None)\n\nCalculate initial xscale amplitude correction coefficients from the history exported from the previous calculation (with xscale_list argument).",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "monitor.html",
    "href": "monitor.html",
    "title": "Monitor",
    "section": "",
    "text": "source\n\nplot_band_set\n\n plot_band_set (bnd, units=0.0041356676623401645, lbl=None, **kwargs)\n\n\nsource\n\n\nplot_bands\n\n plot_bands (bnd, kpnts, units=0.0041356676623401645, decorate=True,\n             lbl=None, **kwargs)\n\n\nsource\n\n\nplot_bands_file\n\n plot_bands_file (fn, units=0.0041356676623401645, decorate=True,\n                  lbl=None, **kwargs)\n\n\nsource\n\n\nrun_alamode\n\n run_alamode (d='phon', prefix='cryst', kpath='cryst', dfset='DFSET',\n              sc='../sc/CONTCAR', o=1, n=0, c2=10, c3=6, born=None,\n              charge=None, skip_fit=False)\n\n\nsource\n\n\nshow_dc_conv\n\n show_dc_conv (bl, kpnts, max_plots=4)\n\n\nsource\n\n\nbuild_bnd_lst\n\n build_bnd_lst (directory='phon', dfset='DFSET', prefix='cryst',\n                kpath='crast', sc='../sc/CONTCAR', order=1, cutoff=10,\n                born=None, charge=None, verbose=False)\n\n\nsource\n\n\nbuild_omega\n\n build_omega (bl, kpnts)\n\n\nsource\n\n\nplot_omega\n\n plot_omega (omega)\n\n\nsource\n\n\nmonitor_phonons\n\n monitor_phonons (directory='phon', dfset='DFSET', prefix='cryst',\n                  kpath='cryst', sc='../sc/CONTCAR', order=1, cutoff=10,\n                  born=None, charge=None, k_list=None, fig_out=None,\n                  once=False)\n\n\nsource\n\n\nplot_stats\n\n plot_stats (confs, T=None, sqrN=False, show=True, plotchi2=False,\n             show_samples=True)\n\n*Plot monitoring histograms for the configuration list in confs. If len(confs)&lt;3 this function is silent.\nconfs - configuration list T - target temperature in Kelvin show - call show() fuction at the end (default:True) show_samples - show individual samples above the histogram*\n\nplot_stats(load_dfset('example/VASP_3C-SiC_calculated/1x1x1/T_300K/DFSET.dat'), \n           T=300, sqrN=True)\n\n\n\n\n\n\n\n\n\nsource\n\n\nmonitor_stats\n\n monitor_stats (T, dfset, plotchi2=False, sqrN=False, once=False)\n\n\nmonitor_stats(T=600, \n              dfset='example/VASP_3C-SiC_calculated/1x1x1/T_600K/DFSET.dat', \n              once=True)\n\n\n\n\n\n\n\n\n\nsource\n\n\nmoving_average\n\n moving_average (x, w)\n\n\nsource\n\n\newma\n\n ewma (data, window)\n\n\nsource\n\n\nplot_hist\n\n plot_hist (v, el, n, l='', alpha=0.2, normal=True, df=3)\n\n\nsource\n\n\nplot_virial_stat\n\n plot_virial_stat (cryst, smpl, T, normal=False)\n\n\nsource\n\n\nplot_acceptance_history\n\n plot_acceptance_history (smpl)\n\n\nsource\n\n\nplot_dofmu_stat\n\n plot_dofmu_stat (cryst, dofmu, skip=10, window=10, normal=False)\n\n\nsource\n\n\nplot_xs_stat\n\n plot_xs_stat (cryst, xsl, skip=10, window=10)",
    "crumbs": [
      "Monitor"
    ]
  }
]